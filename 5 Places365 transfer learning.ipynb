{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from PIL import Image    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('flair-vgg16-data.csv', names=['_id', 'message', 'image_concept', 'published', 'disabled'])\n",
    "df['available'] = 0\n",
    "\n",
    "all_images_path = 'data/all_images'\n",
    "for i, row in df.iterrows():\n",
    "    if os.path.isfile(os.path.join(all_images_path, row['_id'] + '.jpg')):\n",
    "        df.at[i, 'available']= 1    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "published 2628, disabled 5348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>message</th>\n",
       "      <th>image_concept</th>\n",
       "      <th>published</th>\n",
       "      <th>disabled</th>\n",
       "      <th>available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e5836fee917e8d9a8a7b277</td>\n",
       "      <td>endless blues greatbarrierreef australia whits...</td>\n",
       "      <td>seascape water shoal sea turquoise sun tropica...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e58343ded065ad79e312f3d</td>\n",
       "      <td>hamiltonisland</td>\n",
       "      <td>tree travel vacation seashore water hotel isla...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e57dc939e88b6be2ac42800</td>\n",
       "      <td>we are going coconuts for hamiltonisland here ...</td>\n",
       "      <td>relaxation beach sea vacation sand recreation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e55dca437fa5927dcdf02f3</td>\n",
       "      <td>en route to gbr embrace the elevation in luxur...</td>\n",
       "      <td>nature travel diving water sea underwater ocea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e55d69eb9e5b725cd7ba02f</td>\n",
       "      <td>golf course views hamiltonislandgolfcourse whi...</td>\n",
       "      <td>outdoors landscape beach sky nature rural nope...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>5e253779f1b8d48ba5de7d32</td>\n",
       "      <td>colours so bright they hurt your eyes tropical...</td>\n",
       "      <td>outdoors nature scenery landscape water land o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>5e252d334610948976f731e5</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>human person patient therapy massage heel spa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>5e252d334610948976f731e6</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>plant paper text flower blossom</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>5e252d3342307c89757703c0</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>person human finger hand dating face arm</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>5e252d33f7b8d8898b9e841f</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>human person patient massage therapy spa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7976 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id  \\\n",
       "0     5e5836fee917e8d9a8a7b277   \n",
       "1     5e58343ded065ad79e312f3d   \n",
       "2     5e57dc939e88b6be2ac42800   \n",
       "3     5e55dca437fa5927dcdf02f3   \n",
       "4     5e55d69eb9e5b725cd7ba02f   \n",
       "...                        ...   \n",
       "7971  5e253779f1b8d48ba5de7d32   \n",
       "7972  5e252d334610948976f731e5   \n",
       "7973  5e252d334610948976f731e6   \n",
       "7974  5e252d3342307c89757703c0   \n",
       "7975  5e252d33f7b8d8898b9e841f   \n",
       "\n",
       "                                                message  \\\n",
       "0     endless blues greatbarrierreef australia whits...   \n",
       "1                                        hamiltonisland   \n",
       "2     we are going coconuts for hamiltonisland here ...   \n",
       "3     en route to gbr embrace the elevation in luxur...   \n",
       "4     golf course views hamiltonislandgolfcourse whi...   \n",
       "...                                                 ...   \n",
       "7971  colours so bright they hurt your eyes tropical...   \n",
       "7972  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "7973  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "7974  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "7975  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "\n",
       "                                          image_concept  published  disabled  \\\n",
       "0     seascape water shoal sea turquoise sun tropica...          1         0   \n",
       "1     tree travel vacation seashore water hotel isla...          1         0   \n",
       "2     relaxation beach sea vacation sand recreation ...          1         0   \n",
       "3     nature travel diving water sea underwater ocea...          1         0   \n",
       "4     outdoors landscape beach sky nature rural nope...          1         0   \n",
       "...                                                 ...        ...       ...   \n",
       "7971  outdoors nature scenery landscape water land o...          0         1   \n",
       "7972      human person patient therapy massage heel spa          0         1   \n",
       "7973                    plant paper text flower blossom          0         1   \n",
       "7974           person human finger hand dating face arm          0         1   \n",
       "7975           human person patient massage therapy spa          0         1   \n",
       "\n",
       "      available  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "7971          1  \n",
       "7972          1  \n",
       "7973          1  \n",
       "7974          1  \n",
       "7975          1  \n",
       "\n",
       "[7976 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_published = df[(df.published == 1) & (df.available == 1) & df.message.notnull()]\n",
    "\n",
    "df_disabled = df[(df.disabled == 1) & (df.available == 1) & df.message.notnull()]\n",
    "\n",
    "\n",
    "print(f\"published {len(df_published)}, disabled {len(df_disabled)}\")\n",
    "\n",
    "df_all = pd.concat([df_published, df_disabled], ignore_index=True)\n",
    "\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 4785, val 1914, test 1277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df_all, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(val_df, test_size=0.4, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"train {len(train_df)}, val {len(val_df)}, test {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=365, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.embeddings import (\n",
    "    Sentence, \n",
    "    WordEmbeddings, \n",
    "    FlairEmbeddings, \n",
    "    StackedEmbeddings, \n",
    "    DocumentRNNEmbeddings,\n",
    "    BytePairEmbeddings\n",
    ")\n",
    "from flair.training_utils import store_embeddings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def get_pretrain_model():\n",
    "    arch = 'resnet18'\n",
    "\n",
    "    # load the pre-trained weights\n",
    "    model_file = '%s_places365.pth.tar' % arch\n",
    "    if not os.access(model_file, os.W_OK):\n",
    "        weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n",
    "        os.system('wget ' + weight_url)\n",
    "\n",
    "    model = models.__dict__[arch](num_classes=365)\n",
    "    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
    "    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_pretrain_model()\n",
    "\n",
    "\n",
    "model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512, 7, 7])\n",
      "torch.Size([10, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "test_model = get_pretrain_model()\n",
    "test_model = nn.Sequential(*list(test_model.children())[:-2])\n",
    "\n",
    "test_classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    # input 512, 7, 7\n",
    "    # output size: (7 - 1)/1 + 1 = 7\n",
    "    # output tensor: 1 x 7 x 7\n",
    "    nn.Conv2d(512, 1, 1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.AvgPool2d(7)\n",
    ")        \n",
    "\n",
    "test_aap = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "test_sample = test_model(torch.zeros(10,3,224,224))\n",
    "print(test_sample.shape)\n",
    "\n",
    "test_out = test_aap(test_sample)\n",
    "\n",
    "print(test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "published 3116\n",
      "disabled 3227\n",
      "published 1558\n",
      "disabled 1558\n"
     ]
    }
   ],
   "source": [
    "def oversample_df(df):\n",
    "    classes = ['published', 'disabled'] \n",
    "    classes_count = []\n",
    "    for c in classes:    \n",
    "        classes_count.append(len(df.loc[df[c] == 1]))\n",
    "    \n",
    "    max_count = max(classes_count)\n",
    "    resample_ratios = [round(max_count/c) for c in classes_count]\n",
    "            \n",
    "    resampled = []\n",
    "    for i in range(len(resample_ratios)):\n",
    "        c = classes[i]\n",
    "        ratio = resample_ratios[i]        \n",
    "        for r in range(ratio):            \n",
    "            resampled.append(df.loc[df[c] == 1])\n",
    "            \n",
    "    resampled_df = pd.concat(resampled, ignore_index=True)\n",
    "    resampled_df = resampled_df.sample(frac=1)\n",
    "    resampled_df = resampled_df.reset_index(drop=True)\n",
    "    \n",
    "    return resampled_df\n",
    "\n",
    "resampled = oversample_df(train_df)\n",
    "print(f\"published {len(resampled.loc[resampled.published == 1])}\")\n",
    "print(f\"disabled {len(resampled.loc[resampled.disabled == 1])}\")\n",
    "\n",
    "\n",
    "def balance_df(df):\n",
    "    classes = ['published', 'disabled'] \n",
    "    classes_count = []\n",
    "    for c in classes:    \n",
    "        classes_count.append(len(df.loc[df[c] == 1]))\n",
    "    \n",
    "    min_count = min(classes_count)\n",
    "    \n",
    "    resampled = []\n",
    "    for c in classes:\n",
    "        resampled.append(df[df[c] == 1][:min_count])\n",
    "        \n",
    "    resampled_df = pd.concat(resampled, ignore_index=True)\n",
    "    resampled_df = resampled_df.sample(frac=1)\n",
    "    resampled_df = resampled_df.reset_index(drop=True)\n",
    "    \n",
    "    return resampled_df\n",
    "    \n",
    "    \n",
    "resampled = balance_df(train_df)\n",
    "print(f\"published {len(resampled.loc[resampled.published == 1])}\")\n",
    "print(f\"disabled {len(resampled.loc[resampled.disabled == 1])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(df, transformer, oversample=False, batch_size=16):        \n",
    "    if oversample:        \n",
    "        df = oversample_df(df)\n",
    "    else:\n",
    "        df = balance_df(df)\n",
    "        \n",
    "    n_batches = len(df)//batch_size    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        sentences = [Sentence(txt) for txt in df[i:i+batch_size]['message']]\n",
    "        labels = [1 if label else 0 for label in df[i:i+batch_size]['published']]\n",
    "        \n",
    "        images = []\n",
    "        for _id in df[i:i+batch_size]['_id']:\n",
    "            image = Image.open('data/all_images/'+_id+'.jpg').convert('RGB')\n",
    "            images.append(transformer(image).unsqueeze(0))\n",
    "            \n",
    "        image_tensor = torch.cat(images, 0)\n",
    "        \n",
    "        yield sentences, image_tensor, torch.FloatTensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, train loss 0.050079595297575\n",
      "Epoch 0, Batch 20, train loss 0.04431527853012085\n",
      "Epoch 0, Batch 40, train loss 0.037323445081710815\n",
      "Epoch 0, Batch 60, train loss 0.04336617887020111\n",
      "Epoch 0, Batch 80, train loss 0.04194758087396622\n",
      "Epoch 0, Batch 100, train loss 0.04303673282265663\n",
      "Epoch 0, Batch 120, train loss 0.043144021183252335\n",
      "Epoch 0, Batch 140, train loss 0.039126165211200714\n",
      "Epoch 0, Batch 160, train loss 0.0434381440281868\n",
      "Epoch 0, Batch 180, train loss 0.03743201866745949\n",
      "Epoch 0, Batch 200, train loss 0.038320329040288925\n",
      "Epoch 0, Batch 220, train loss 0.032621629536151886\n",
      "Epoch 0, Batch 240, train loss 0.037512682378292084\n",
      "Epoch 0, Batch 260, train loss 0.038997650146484375\n",
      "Epoch 0, Batch 280, train loss 0.03067244589328766\n",
      "Epoch 0, Batch 300, train loss 0.042745426297187805\n",
      "Epoch 0, Batch 320, train loss 0.03372036665678024\n",
      "Epoch 0, Batch 340, train loss 0.03968781977891922\n",
      "Epoch 0, Batch 360, train loss 0.029326818883419037\n",
      "Epoch 0, Batch 380, train loss 0.039998479187488556\n",
      "> Epoch 0, train loss 0.03950491656588771\n",
      "> Epoch 0, val loss 0.037322055646615435, accuracy 0.6821705426356589, f1_score 0.6818646616541353\n",
      "Saved model.\n",
      "Epoch 1, Batch 0, train loss 0.04246353358030319\n",
      "Epoch 1, Batch 20, train loss 0.04411909356713295\n",
      "Epoch 1, Batch 40, train loss 0.03855156898498535\n",
      "Epoch 1, Batch 60, train loss 0.048413828015327454\n",
      "Epoch 1, Batch 80, train loss 0.04061578959226608\n",
      "Epoch 1, Batch 100, train loss 0.045004889369010925\n",
      "Epoch 1, Batch 120, train loss 0.03615952655673027\n",
      "Epoch 1, Batch 140, train loss 0.03078988753259182\n",
      "Epoch 1, Batch 160, train loss 0.042495738714933395\n",
      "Epoch 1, Batch 180, train loss 0.04484919458627701\n",
      "Epoch 1, Batch 200, train loss 0.052762165665626526\n",
      "Epoch 1, Batch 220, train loss 0.035791706293821335\n",
      "Epoch 1, Batch 240, train loss 0.040102407336235046\n",
      "Epoch 1, Batch 260, train loss 0.027583325281739235\n",
      "Epoch 1, Batch 280, train loss 0.03699919581413269\n",
      "Epoch 1, Batch 300, train loss 0.039851557463407516\n",
      "Epoch 1, Batch 320, train loss 0.03679056838154793\n",
      "Epoch 1, Batch 340, train loss 0.03385736420750618\n",
      "Epoch 1, Batch 360, train loss 0.03590339422225952\n",
      "Epoch 1, Batch 380, train loss 0.03342606499791145\n",
      "> Epoch 1, train loss 0.03771528038771093\n",
      "> Epoch 1, val loss 0.03713702411614647, accuracy 0.6891472868217055, f1_score 0.6878550769938166\n",
      "Saved model.\n",
      "Epoch 2, Batch 0, train loss 0.03799978643655777\n",
      "Epoch 2, Batch 20, train loss 0.03033224679529667\n",
      "Epoch 2, Batch 40, train loss 0.04741528630256653\n",
      "Epoch 2, Batch 60, train loss 0.03980135917663574\n",
      "Epoch 2, Batch 80, train loss 0.05589010566473007\n",
      "Epoch 2, Batch 100, train loss 0.04066571593284607\n",
      "Epoch 2, Batch 120, train loss 0.03801223635673523\n",
      "Epoch 2, Batch 140, train loss 0.03890683501958847\n",
      "Epoch 2, Batch 160, train loss 0.04512946680188179\n",
      "Epoch 2, Batch 180, train loss 0.030743300914764404\n",
      "Epoch 2, Batch 200, train loss 0.03427238389849663\n",
      "Epoch 2, Batch 220, train loss 0.036769330501556396\n",
      "Epoch 2, Batch 240, train loss 0.032957836985588074\n",
      "Epoch 2, Batch 260, train loss 0.028479279950261116\n",
      "Epoch 2, Batch 280, train loss 0.0327911414206028\n",
      "Epoch 2, Batch 300, train loss 0.03329477459192276\n",
      "Epoch 2, Batch 320, train loss 0.03137925639748573\n",
      "Epoch 2, Batch 340, train loss 0.0427708700299263\n",
      "Epoch 2, Batch 360, train loss 0.034584932029247284\n",
      "Epoch 2, Batch 380, train loss 0.04053715988993645\n",
      "> Epoch 2, train loss 0.03738127530664182\n",
      "> Epoch 2, val loss 0.03618027974468793, accuracy 0.7023255813953488, f1_score 0.7023141326269383\n",
      "Saved model.\n",
      "Epoch 3, Batch 0, train loss 0.04243022948503494\n",
      "Epoch 3, Batch 20, train loss 0.0384136438369751\n",
      "Epoch 3, Batch 40, train loss 0.028951002284884453\n",
      "Epoch 3, Batch 60, train loss 0.04554399847984314\n",
      "Epoch 3, Batch 80, train loss 0.03112201765179634\n",
      "Epoch 3, Batch 100, train loss 0.03440196067094803\n",
      "Epoch 3, Batch 120, train loss 0.049371615052223206\n",
      "Epoch 3, Batch 140, train loss 0.047587424516677856\n",
      "Epoch 3, Batch 160, train loss 0.037608541548252106\n",
      "Epoch 3, Batch 180, train loss 0.04228319227695465\n",
      "Epoch 3, Batch 200, train loss 0.029488205909729004\n",
      "Epoch 3, Batch 220, train loss 0.030255155637860298\n",
      "Epoch 3, Batch 240, train loss 0.04934770241379738\n",
      "Epoch 3, Batch 260, train loss 0.03493770956993103\n",
      "Epoch 3, Batch 280, train loss 0.03228079527616501\n",
      "Epoch 3, Batch 300, train loss 0.04281514510512352\n",
      "Epoch 3, Batch 320, train loss 0.03480413928627968\n",
      "Epoch 3, Batch 340, train loss 0.03299479931592941\n",
      "Epoch 3, Batch 360, train loss 0.044832319021224976\n",
      "Epoch 3, Batch 380, train loss 0.03865613043308258\n",
      "> Epoch 3, train loss 0.03662564835111632\n",
      "> Epoch 3, val loss 0.03563209009724994, accuracy 0.7046511627906977, f1_score 0.7046495654384285\n",
      "Saved model.\n",
      "Epoch 4, Batch 0, train loss 0.0467691645026207\n",
      "Epoch 4, Batch 20, train loss 0.035237591713666916\n",
      "Epoch 4, Batch 40, train loss 0.030081959441304207\n",
      "Epoch 4, Batch 60, train loss 0.03318522125482559\n",
      "Epoch 4, Batch 80, train loss 0.03588023781776428\n",
      "Epoch 4, Batch 100, train loss 0.03257080912590027\n",
      "Epoch 4, Batch 120, train loss 0.030785975977778435\n",
      "Epoch 4, Batch 140, train loss 0.02930595353245735\n",
      "Epoch 4, Batch 160, train loss 0.027705885469913483\n",
      "Epoch 4, Batch 180, train loss 0.03552202135324478\n",
      "Epoch 4, Batch 200, train loss 0.04060160368680954\n",
      "Epoch 4, Batch 220, train loss 0.05027720332145691\n",
      "Epoch 4, Batch 240, train loss 0.036173224449157715\n",
      "Epoch 4, Batch 260, train loss 0.03230232000350952\n",
      "Epoch 4, Batch 280, train loss 0.05482782796025276\n",
      "Epoch 4, Batch 300, train loss 0.0378149040043354\n",
      "Epoch 4, Batch 320, train loss 0.03203554451465607\n",
      "Epoch 4, Batch 340, train loss 0.0426623672246933\n",
      "Epoch 4, Batch 360, train loss 0.03917410969734192\n",
      "Epoch 4, Batch 380, train loss 0.051441874355077744\n",
      "> Epoch 4, train loss 0.036556359680597665\n",
      "> Epoch 4, val loss 0.035760072682255, accuracy 0.7046511627906977, f1_score 0.7046112237998647\n",
      "No improvement.\n",
      "Epoch 5, Batch 0, train loss 0.0381198525428772\n",
      "Epoch 5, Batch 20, train loss 0.04216303676366806\n",
      "Epoch 5, Batch 40, train loss 0.03217161446809769\n",
      "Epoch 5, Batch 60, train loss 0.037676725536584854\n",
      "Epoch 5, Batch 80, train loss 0.02725560963153839\n",
      "Epoch 5, Batch 100, train loss 0.036449745297431946\n",
      "Epoch 5, Batch 120, train loss 0.03789015859365463\n",
      "Epoch 5, Batch 140, train loss 0.032267939299345016\n",
      "Epoch 5, Batch 160, train loss 0.03551133722066879\n",
      "Epoch 5, Batch 180, train loss 0.03168356418609619\n",
      "Epoch 5, Batch 200, train loss 0.051368892192840576\n",
      "Epoch 5, Batch 220, train loss 0.02993491291999817\n",
      "Epoch 5, Batch 240, train loss 0.017752021551132202\n",
      "Epoch 5, Batch 260, train loss 0.030157893896102905\n",
      "Epoch 5, Batch 280, train loss 0.04330916702747345\n",
      "Epoch 5, Batch 300, train loss 0.025252286344766617\n",
      "Epoch 5, Batch 320, train loss 0.057315267622470856\n",
      "Epoch 5, Batch 340, train loss 0.04093918204307556\n",
      "Epoch 5, Batch 360, train loss 0.03271986544132233\n",
      "Epoch 5, Batch 380, train loss 0.03653289005160332\n",
      "> Epoch 5, train loss 0.03595935350691278\n",
      "> Epoch 5, val loss 0.03572146548319233, accuracy 0.7007751937984497, f1_score 0.7007399465353771\n",
      "No improvement.\n",
      "Epoch 6, Batch 0, train loss 0.03623718023300171\n",
      "Epoch 6, Batch 20, train loss 0.0328981876373291\n",
      "Epoch 6, Batch 40, train loss 0.035376813262701035\n",
      "Epoch 6, Batch 60, train loss 0.028424212709069252\n",
      "Epoch 6, Batch 80, train loss 0.03248852118849754\n",
      "Epoch 6, Batch 100, train loss 0.03539130091667175\n",
      "Epoch 6, Batch 120, train loss 0.031292762607336044\n",
      "Epoch 6, Batch 140, train loss 0.0401056669652462\n",
      "Epoch 6, Batch 160, train loss 0.033678989857435226\n",
      "Epoch 6, Batch 180, train loss 0.040243037045001984\n",
      "Epoch 6, Batch 200, train loss 0.032075271010398865\n",
      "Epoch 6, Batch 220, train loss 0.034951165318489075\n",
      "Epoch 6, Batch 240, train loss 0.028680043295025826\n",
      "Epoch 6, Batch 260, train loss 0.03429733216762543\n",
      "Epoch 6, Batch 280, train loss 0.03694948926568031\n",
      "Epoch 6, Batch 300, train loss 0.026552725583314896\n",
      "Epoch 6, Batch 320, train loss 0.04368141293525696\n",
      "Epoch 6, Batch 340, train loss 0.03296755254268646\n",
      "Epoch 6, Batch 360, train loss 0.02893729880452156\n",
      "Epoch 6, Batch 380, train loss 0.026871057227253914\n",
      "> Epoch 6, train loss 0.03595713693393098\n",
      "> Epoch 6, val loss 0.03585395704406177, accuracy 0.7031007751937984, f1_score 0.6989762377239004\n",
      "No improvement.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 0, train loss 0.04290837049484253\n",
      "Epoch 7, Batch 20, train loss 0.03222533315420151\n",
      "Epoch 7, Batch 40, train loss 0.0440770648419857\n",
      "Epoch 7, Batch 60, train loss 0.02957294136285782\n",
      "Epoch 7, Batch 80, train loss 0.03239576518535614\n",
      "Epoch 7, Batch 100, train loss 0.023778628557920456\n",
      "Epoch 7, Batch 120, train loss 0.04036487638950348\n",
      "Epoch 7, Batch 140, train loss 0.04378246143460274\n",
      "Epoch 7, Batch 160, train loss 0.04232189804315567\n",
      "Epoch 7, Batch 180, train loss 0.04541537165641785\n",
      "Epoch 7, Batch 200, train loss 0.03979666531085968\n",
      "Epoch 7, Batch 220, train loss 0.037927836179733276\n",
      "Epoch 7, Batch 240, train loss 0.027853824198246002\n",
      "Epoch 7, Batch 260, train loss 0.04262251406908035\n",
      "Epoch 7, Batch 280, train loss 0.03131712228059769\n",
      "Epoch 7, Batch 300, train loss 0.02355280891060829\n",
      "Epoch 7, Batch 320, train loss 0.03134436532855034\n",
      "Epoch 7, Batch 340, train loss 0.028039343655109406\n",
      "Epoch 7, Batch 360, train loss 0.02802964299917221\n",
      "Epoch 7, Batch 380, train loss 0.04386816918849945\n",
      "> Epoch 7, train loss 0.035840885183064324\n",
      "> Epoch 7, val loss 0.03536453050698421, accuracy 0.7124031007751938, f1_score 0.7112075649992669\n",
      "Saved model.\n",
      "Epoch 8, Batch 0, train loss 0.03119850344955921\n",
      "Epoch 8, Batch 20, train loss 0.03197671100497246\n",
      "Epoch 8, Batch 40, train loss 0.03691365569829941\n",
      "Epoch 8, Batch 60, train loss 0.025287732481956482\n",
      "Epoch 8, Batch 80, train loss 0.02808523364365101\n",
      "Epoch 8, Batch 100, train loss 0.037900686264038086\n",
      "Epoch 8, Batch 120, train loss 0.028750978410243988\n",
      "Epoch 8, Batch 140, train loss 0.03049387037754059\n",
      "Epoch 8, Batch 160, train loss 0.02503419667482376\n",
      "Epoch 8, Batch 180, train loss 0.0227804072201252\n",
      "Epoch 8, Batch 200, train loss 0.02798953838646412\n",
      "Epoch 8, Batch 220, train loss 0.039833810180425644\n",
      "Epoch 8, Batch 240, train loss 0.04068295285105705\n",
      "Epoch 8, Batch 260, train loss 0.032589539885520935\n",
      "Epoch 8, Batch 280, train loss 0.044239591807127\n",
      "Epoch 8, Batch 300, train loss 0.03188305348157883\n",
      "Epoch 8, Batch 320, train loss 0.031648218631744385\n",
      "Epoch 8, Batch 340, train loss 0.03342317044734955\n",
      "Epoch 8, Batch 360, train loss 0.03928055241703987\n",
      "Epoch 8, Batch 380, train loss 0.041121724992990494\n",
      "> Epoch 8, train loss 0.035771803587707984\n",
      "> Epoch 8, val loss 0.036378469092901364, accuracy 0.6953488372093023, f1_score 0.6876130313126391\n",
      "No improvement.\n",
      "Epoch 9, Batch 0, train loss 0.03516422584652901\n",
      "Epoch 9, Batch 20, train loss 0.0435989648103714\n",
      "Epoch 9, Batch 40, train loss 0.035527944564819336\n",
      "Epoch 9, Batch 60, train loss 0.06295507401227951\n",
      "Epoch 9, Batch 80, train loss 0.043495871126651764\n",
      "Epoch 9, Batch 100, train loss 0.03252824768424034\n",
      "Epoch 9, Batch 120, train loss 0.03060828521847725\n",
      "Epoch 9, Batch 140, train loss 0.039350174367427826\n",
      "Epoch 9, Batch 160, train loss 0.03879692777991295\n",
      "Epoch 9, Batch 180, train loss 0.03581369295716286\n",
      "Epoch 9, Batch 200, train loss 0.0414537712931633\n",
      "Epoch 9, Batch 220, train loss 0.033493030816316605\n",
      "Epoch 9, Batch 240, train loss 0.03876175358891487\n",
      "Epoch 9, Batch 260, train loss 0.029740413650870323\n",
      "Epoch 9, Batch 280, train loss 0.03703384846448898\n",
      "Epoch 9, Batch 300, train loss 0.03191142529249191\n",
      "Epoch 9, Batch 320, train loss 0.030533602461218834\n",
      "Epoch 9, Batch 340, train loss 0.03899822384119034\n",
      "Epoch 9, Batch 360, train loss 0.040651835501194\n",
      "Epoch 9, Batch 380, train loss 0.02848445624113083\n",
      "> Epoch 9, train loss 0.03586190460646508\n",
      "> Epoch 9, val loss 0.03609016107958417, accuracy 0.7077519379844961, f1_score 0.7067607289829512\n",
      "No improvement.\n",
      "Epoch 10, Batch 0, train loss 0.03589009866118431\n",
      "Epoch 10, Batch 20, train loss 0.03912581130862236\n",
      "Epoch 10, Batch 40, train loss 0.03211461007595062\n",
      "Epoch 10, Batch 60, train loss 0.0388716384768486\n",
      "Epoch 10, Batch 80, train loss 0.038857221603393555\n",
      "Epoch 10, Batch 100, train loss 0.03331553190946579\n",
      "Epoch 10, Batch 120, train loss 0.027355125173926353\n",
      "Epoch 10, Batch 140, train loss 0.02666841261088848\n",
      "Epoch 10, Batch 160, train loss 0.030359216034412384\n",
      "Epoch 10, Batch 180, train loss 0.029502850025892258\n",
      "Epoch 10, Batch 200, train loss 0.03631444647908211\n",
      "Epoch 10, Batch 220, train loss 0.028712136670947075\n",
      "Epoch 10, Batch 240, train loss 0.03170880302786827\n",
      "Epoch 10, Batch 260, train loss 0.036667607724666595\n",
      "Epoch 10, Batch 280, train loss 0.050905968993902206\n",
      "Epoch 10, Batch 300, train loss 0.03471061959862709\n",
      "Epoch 10, Batch 320, train loss 0.039557334035634995\n",
      "Epoch 10, Batch 340, train loss 0.04346037283539772\n",
      "Epoch 10, Batch 360, train loss 0.03988511115312576\n",
      "Epoch 10, Batch 380, train loss 0.035107459872961044\n",
      "> Epoch 10, train loss 0.03571933622091854\n",
      "> Epoch 10, val loss 0.03542634327282277, accuracy 0.703875968992248, f1_score 0.7009314712001341\n",
      "No improvement.\n",
      "Epoch 11, Batch 0, train loss 0.029134906828403473\n",
      "Epoch 11, Batch 20, train loss 0.03318142890930176\n",
      "Epoch 11, Batch 40, train loss 0.03377540409564972\n",
      "Epoch 11, Batch 60, train loss 0.044885024428367615\n",
      "Epoch 11, Batch 80, train loss 0.03813495859503746\n",
      "Epoch 11, Batch 100, train loss 0.036961328238248825\n",
      "Epoch 11, Batch 120, train loss 0.03043185919523239\n",
      "Epoch 11, Batch 140, train loss 0.027189988642930984\n",
      "Epoch 11, Batch 160, train loss 0.029288168996572495\n",
      "Epoch 11, Batch 180, train loss 0.02502489648759365\n",
      "Epoch 11, Batch 200, train loss 0.03837493807077408\n",
      "Epoch 11, Batch 220, train loss 0.038867272436618805\n",
      "Epoch 11, Batch 240, train loss 0.04753364622592926\n",
      "Epoch 11, Batch 260, train loss 0.033901020884513855\n",
      "Epoch 11, Batch 280, train loss 0.026852663606405258\n",
      "Epoch 11, Batch 300, train loss 0.040075503289699554\n",
      "Epoch 11, Batch 320, train loss 0.03955855965614319\n",
      "Epoch 11, Batch 340, train loss 0.030723143368959427\n",
      "Epoch 11, Batch 360, train loss 0.03468930721282959\n",
      "Epoch 11, Batch 380, train loss 0.03748074173927307\n",
      "> Epoch 11, train loss 0.035208068899639997\n",
      "> Epoch 11, val loss 0.03538083337074102, accuracy 0.7077519379844961, f1_score 0.7054107670174906\n",
      "No improvement.\n",
      "Epoch 12, Batch 0, train loss 0.040290966629981995\n",
      "Epoch 12, Batch 20, train loss 0.04471491277217865\n",
      "Epoch 12, Batch 40, train loss 0.021905314177274704\n",
      "Epoch 12, Batch 60, train loss 0.03869134187698364\n",
      "Epoch 12, Batch 80, train loss 0.030738310888409615\n",
      "Epoch 12, Batch 100, train loss 0.04134300723671913\n",
      "Epoch 12, Batch 120, train loss 0.03471793979406357\n",
      "Epoch 12, Batch 140, train loss 0.04030746594071388\n",
      "Epoch 12, Batch 160, train loss 0.03832179307937622\n",
      "Epoch 12, Batch 180, train loss 0.02401840314269066\n",
      "Epoch 12, Batch 200, train loss 0.047213342040777206\n",
      "Epoch 12, Batch 220, train loss 0.02283809334039688\n",
      "Epoch 12, Batch 240, train loss 0.04083208739757538\n",
      "Epoch 12, Batch 260, train loss 0.04384273290634155\n",
      "Epoch 12, Batch 280, train loss 0.035207703709602356\n",
      "Epoch 12, Batch 300, train loss 0.02920924499630928\n",
      "Epoch 12, Batch 320, train loss 0.0384611114859581\n",
      "Epoch 12, Batch 340, train loss 0.030253121629357338\n",
      "Epoch 12, Batch 360, train loss 0.04787302762269974\n",
      "Epoch 12, Batch 380, train loss 0.03767402470111847\n",
      "> Epoch 12, train loss 0.03582469167796554\n",
      "> Epoch 12, val loss 0.035242211264233256, accuracy 0.7093023255813954, f1_score 0.7091119661866336\n",
      "Saved model.\n",
      "Epoch 13, Batch 0, train loss 0.023593958467245102\n",
      "Epoch 13, Batch 20, train loss 0.04204416647553444\n",
      "Epoch 13, Batch 40, train loss 0.020264647901058197\n",
      "Epoch 13, Batch 60, train loss 0.04304805397987366\n",
      "Epoch 13, Batch 80, train loss 0.04019741341471672\n",
      "Epoch 13, Batch 100, train loss 0.04504367709159851\n",
      "Epoch 13, Batch 120, train loss 0.032127127051353455\n",
      "Epoch 13, Batch 140, train loss 0.03922627121210098\n",
      "Epoch 13, Batch 160, train loss 0.03568406030535698\n",
      "Epoch 13, Batch 180, train loss 0.024969525635242462\n",
      "Epoch 13, Batch 200, train loss 0.03188963979482651\n",
      "Epoch 13, Batch 220, train loss 0.028791114687919617\n",
      "Epoch 13, Batch 240, train loss 0.03382042050361633\n",
      "Epoch 13, Batch 260, train loss 0.028060121461749077\n",
      "Epoch 13, Batch 280, train loss 0.0385761484503746\n",
      "Epoch 13, Batch 300, train loss 0.04283273592591286\n",
      "Epoch 13, Batch 320, train loss 0.025820642709732056\n",
      "Epoch 13, Batch 340, train loss 0.0347570925951004\n",
      "Epoch 13, Batch 360, train loss 0.03156809136271477\n",
      "Epoch 13, Batch 380, train loss 0.042096637189388275\n",
      "> Epoch 13, train loss 0.03581066007458523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch 13, val loss 0.03512898736683897, accuracy 0.7131782945736435, f1_score 0.7125973062545763\n",
      "Saved model.\n",
      "Epoch 14, Batch 0, train loss 0.03153013810515404\n",
      "Epoch 14, Batch 20, train loss 0.03529452160000801\n",
      "Epoch 14, Batch 40, train loss 0.03581370785832405\n",
      "Epoch 14, Batch 60, train loss 0.032160550355911255\n",
      "Epoch 14, Batch 80, train loss 0.0385383702814579\n",
      "Epoch 14, Batch 100, train loss 0.04002279043197632\n",
      "Epoch 14, Batch 120, train loss 0.036396853625774384\n",
      "Epoch 14, Batch 140, train loss 0.029498476535081863\n",
      "Epoch 14, Batch 160, train loss 0.031843654811382294\n",
      "Epoch 14, Batch 180, train loss 0.03488294780254364\n",
      "Epoch 14, Batch 200, train loss 0.03212668374180794\n",
      "Epoch 14, Batch 220, train loss 0.04549304395914078\n",
      "Epoch 14, Batch 240, train loss 0.039179615676403046\n",
      "Epoch 14, Batch 260, train loss 0.039079584181308746\n",
      "Epoch 14, Batch 280, train loss 0.043909117579460144\n",
      "Epoch 14, Batch 300, train loss 0.032503947615623474\n",
      "Epoch 14, Batch 320, train loss 0.029529733583331108\n",
      "Epoch 14, Batch 340, train loss 0.02584407664835453\n",
      "Epoch 14, Batch 360, train loss 0.03586747869849205\n",
      "Epoch 14, Batch 380, train loss 0.02959909662604332\n",
      "> Epoch 14, train loss 0.03517599434633088\n",
      "> Epoch 14, val loss 0.035350417674973954, accuracy 0.7155038759689922, f1_score 0.7149857772827838\n",
      "No improvement.\n",
      "Epoch 15, Batch 0, train loss 0.047133758664131165\n",
      "Epoch 15, Batch 20, train loss 0.036821961402893066\n",
      "Epoch 15, Batch 40, train loss 0.02244560234248638\n",
      "Epoch 15, Batch 60, train loss 0.020850446075201035\n",
      "Epoch 15, Batch 80, train loss 0.035527922213077545\n",
      "Epoch 15, Batch 100, train loss 0.035576481372117996\n",
      "Epoch 15, Batch 120, train loss 0.03316660597920418\n",
      "Epoch 15, Batch 140, train loss 0.03911041468381882\n",
      "Epoch 15, Batch 160, train loss 0.043273698538541794\n",
      "Epoch 15, Batch 180, train loss 0.033649247139692307\n",
      "Epoch 15, Batch 200, train loss 0.02918153814971447\n",
      "Epoch 15, Batch 220, train loss 0.02187945693731308\n",
      "Epoch 15, Batch 240, train loss 0.035662516951560974\n",
      "Epoch 15, Batch 260, train loss 0.04030762240290642\n",
      "Epoch 15, Batch 280, train loss 0.03533488139510155\n",
      "Epoch 15, Batch 300, train loss 0.040188685059547424\n",
      "Epoch 15, Batch 320, train loss 0.0309721902012825\n",
      "Epoch 15, Batch 340, train loss 0.05328688025474548\n",
      "Epoch 15, Batch 360, train loss 0.036809079349040985\n",
      "Epoch 15, Batch 380, train loss 0.03729965165257454\n",
      "> Epoch 15, train loss 0.035697773862445124\n",
      "> Epoch 15, val loss 0.035685581523318625, accuracy 0.7077519379844961, f1_score 0.7075366458693527\n",
      "No improvement.\n",
      "Epoch 16, Batch 0, train loss 0.030527504161000252\n",
      "Epoch 16, Batch 20, train loss 0.045119479298591614\n",
      "Epoch 16, Batch 40, train loss 0.032546695321798325\n",
      "Epoch 16, Batch 60, train loss 0.04566928744316101\n",
      "Epoch 16, Batch 80, train loss 0.03748645260930061\n",
      "Epoch 16, Batch 100, train loss 0.03177899122238159\n",
      "Epoch 16, Batch 120, train loss 0.02139703556895256\n",
      "Epoch 16, Batch 140, train loss 0.035522133111953735\n",
      "Epoch 16, Batch 160, train loss 0.03845136985182762\n",
      "Epoch 16, Batch 180, train loss 0.04790972173213959\n",
      "Epoch 16, Batch 200, train loss 0.029571326449513435\n",
      "Epoch 16, Batch 220, train loss 0.0295652374625206\n",
      "Epoch 16, Batch 240, train loss 0.032467909157276154\n",
      "Epoch 16, Batch 260, train loss 0.03667677938938141\n",
      "Epoch 16, Batch 280, train loss 0.03243393450975418\n",
      "Epoch 16, Batch 300, train loss 0.032580599188804626\n",
      "Epoch 16, Batch 320, train loss 0.027612444013357162\n",
      "Epoch 16, Batch 340, train loss 0.03863723576068878\n",
      "Epoch 16, Batch 360, train loss 0.04472587630152702\n",
      "Epoch 16, Batch 380, train loss 0.0351213775575161\n",
      "> Epoch 16, train loss 0.03542347856825615\n",
      "> Epoch 16, val loss 0.035136356187421225, accuracy 0.7108527131782946, f1_score 0.7104683760848335\n",
      "No improvement.\n",
      "Epoch 17, Batch 0, train loss 0.03829894959926605\n",
      "Epoch 17, Batch 20, train loss 0.03471224009990692\n",
      "Epoch 17, Batch 40, train loss 0.0317080058157444\n",
      "Epoch 17, Batch 60, train loss 0.02991068921983242\n",
      "Epoch 17, Batch 80, train loss 0.02387387864291668\n",
      "Epoch 17, Batch 100, train loss 0.03474663943052292\n",
      "Epoch 17, Batch 120, train loss 0.03786301612854004\n",
      "Epoch 17, Batch 140, train loss 0.04140704125165939\n",
      "Epoch 17, Batch 160, train loss 0.0365586057305336\n",
      "Epoch 17, Batch 180, train loss 0.03976365178823471\n",
      "Epoch 17, Batch 200, train loss 0.03883952647447586\n",
      "Epoch 17, Batch 220, train loss 0.04032527655363083\n",
      "Epoch 17, Batch 240, train loss 0.03048686683177948\n",
      "Epoch 17, Batch 260, train loss 0.05133252590894699\n",
      "Epoch 17, Batch 280, train loss 0.03344148397445679\n",
      "Epoch 17, Batch 300, train loss 0.04535661265254021\n",
      "Epoch 17, Batch 320, train loss 0.04047927260398865\n",
      "Epoch 17, Batch 340, train loss 0.037164315581321716\n",
      "Epoch 17, Batch 360, train loss 0.029265277087688446\n",
      "Epoch 17, Batch 380, train loss 0.03710572049021721\n",
      "> Epoch 17, train loss 0.035284376207368524\n",
      "> Epoch 17, val loss 0.035231694463611574, accuracy 0.7085271317829457, f1_score 0.7077621609115622\n",
      "No improvement.\n",
      "Epoch 18, Batch 0, train loss 0.03337103873491287\n",
      "Epoch 18, Batch 20, train loss 0.03093397617340088\n",
      "Epoch 18, Batch 40, train loss 0.027658963575959206\n",
      "Epoch 18, Batch 60, train loss 0.05096355080604553\n",
      "Epoch 18, Batch 80, train loss 0.0389208048582077\n",
      "Epoch 18, Batch 100, train loss 0.03948712348937988\n",
      "Epoch 18, Batch 120, train loss 0.03545989841222763\n",
      "Epoch 18, Batch 140, train loss 0.03225784748792648\n",
      "Epoch 18, Batch 160, train loss 0.04294159263372421\n",
      "Epoch 18, Batch 180, train loss 0.029545828700065613\n",
      "Epoch 18, Batch 200, train loss 0.03949626535177231\n",
      "Epoch 18, Batch 220, train loss 0.03477860614657402\n",
      "Epoch 18, Batch 240, train loss 0.04450932517647743\n",
      "Epoch 18, Batch 260, train loss 0.029489628970623016\n",
      "Epoch 18, Batch 280, train loss 0.028889961540699005\n",
      "Epoch 18, Batch 300, train loss 0.040920209139585495\n",
      "Epoch 18, Batch 320, train loss 0.03729413449764252\n",
      "Epoch 18, Batch 340, train loss 0.027429834008216858\n",
      "Epoch 18, Batch 360, train loss 0.03334702178835869\n",
      "Epoch 18, Batch 380, train loss 0.027979237958788872\n",
      "> Epoch 18, train loss 0.035377074200404514\n",
      "> Epoch 18, val loss 0.035270394581232885, accuracy 0.710077519379845, f1_score 0.7098515519568153\n",
      "No improvement.\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "    \n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "#         self.document_embeddings = DocumentRNNEmbeddings([\n",
    "#             WordEmbeddings('twitter'),\n",
    "#         ], hidden_size=128)\n",
    "        \n",
    "        pretrained_model = get_pretrain_model()\n",
    "        pretrained_model = nn.Sequential(*list(pretrained_model.children())[:-2])\n",
    "        for param in pretrained_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.pretrained_model = pretrained_model\n",
    "\n",
    "        self.adaptive_avg_pool_2d = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Linear(512, 1)\n",
    "        \n",
    "#         self.fc = nn.Linear(2048*10*10, 1)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, sentences, images):\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "#         self.document_embeddings.embed(sentences)\n",
    "        \n",
    "#         text_embedding_list = [\n",
    "#             s.embedding.unsqueeze(0) for s in sentences\n",
    "#         ]\n",
    "        \n",
    "#         text_embedding_tensor = torch.cat(text_embedding_list, 0).cuda()\n",
    "        \n",
    "#         if train_on_gpu:\n",
    "#             images = images.cuda()\n",
    "            \n",
    "#         image_tensor = self.vgg16(images)\n",
    "#         image_tensor = image_tensor.view(batch_size, -1)\n",
    "        \n",
    "#         input_tensor = torch.cat([text_embedding_tensor, image_tensor], 1)\n",
    "        \n",
    "        input_tensor = images.cuda()\n",
    "        out = self.pretrained_model(input_tensor)                \n",
    "        out = self.adaptive_avg_pool_2d(out)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.fc(out)\n",
    "        #input_tensor = input_tensor.view(batch_size, -1)\n",
    "        \n",
    "        #print(input_tensor.shape)\n",
    "        #out = self.sig(self.fc(input_tensor))\n",
    "        #out = self.sig(input_tensor)\n",
    "        return out\n",
    "    \n",
    "\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "   std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "\n",
    "image_dimension = 224\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(image_dimension),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])        \n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((image_dimension, image_dimension)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize    \n",
    "])\n",
    "\n",
    "    \n",
    "\n",
    "def visualise_data():\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    num_of_samples = 20\n",
    "    num_cols = 5\n",
    "    for i, (sentences, images, labels) in enumerate(get_batches(train_df, train_transform)):\n",
    "        if i >= num_of_samples:\n",
    "            break\n",
    "        \n",
    "        ax = fig.add_subplot(num_of_samples//num_cols + 1, num_cols, i+1, xticks=[], yticks=[])\n",
    "        image = images[0]\n",
    "        image = inv_normalize(image)\n",
    "        plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "        label = labels[0]\n",
    "        ax.set_title(f\"{label}\")\n",
    "        \n",
    "        \n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "def train_model(model, epochs, lr, train_df, val_df, checkpoint_file, early_stopping=5):        \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.8)\n",
    "    best_loss = np.inf\n",
    "    no_improvement = 0\n",
    "\n",
    "    if train_on_gpu:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    for epoch in range(epochs):        \n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        total_train = 0\n",
    "        total_val = 0\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        # Train\n",
    "        model.train()        \n",
    "        for i, (sentences, images, labels) in enumerate(get_batches(train_df, train_transform, True)):         \n",
    "            if train_on_gpu:\n",
    "                labels = labels.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = model(sentences, images)\n",
    "            loss = criterion(out.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            #nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            total_train += labels.size(0)\n",
    "            \n",
    "            store_embeddings(sentences, 'cpu')\n",
    "            \n",
    "            if i % 20 == 0:\n",
    "                print(f\"Epoch {epoch}, Batch {i}, train loss {loss.item()/labels.size(0)}\")\n",
    "            \n",
    "            \n",
    "        train_loss = total_train_loss/total_train\n",
    "        print(f\"> Epoch {epoch}, train loss {train_loss}\")\n",
    "        \n",
    "        \n",
    "        # Eval\n",
    "        model.eval()\n",
    "        all_labels = np.array([])\n",
    "        all_pred = np.array([])        \n",
    "        for sentences, images, labels in get_batches(val_df, test_transform):\n",
    "            if train_on_gpu:\n",
    "                labels = labels.cuda()\n",
    "            \n",
    "            out = model(sentences, images)\n",
    "            loss = criterion(out.squeeze(), labels)\n",
    "            total_val_loss += loss.item()\n",
    "            total_val += labels.size(0)\n",
    "                                \n",
    "            pred = torch.round(torch.sigmoid(out.squeeze()))\n",
    "            \n",
    "            # for matrix\n",
    "            pred_np = pred.data.cpu().numpy() if train_on_gpu else pred.data.numpy()\n",
    "            labels_np = labels.data.cpu().numpy() if train_on_gpu else labels.data.numpy()                    \n",
    "            all_pred = np.concatenate([all_pred, pred_np])\n",
    "            all_labels = np.concatenate([all_labels, labels_np])\n",
    "                        \n",
    "            # clear memory\n",
    "            store_embeddings(sentences, 'cpu')\n",
    "            \n",
    "            \n",
    "        val_loss = total_val_loss / total_val\n",
    "        f1 = f1_score(all_labels, all_pred, average='weighted')\n",
    "        acc = accuracy_score(all_labels, all_pred)\n",
    "        \n",
    "        print(f\"> Epoch {epoch}, val loss {val_loss}, accuracy {acc}, f1_score {f1}\")\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            no_improvement = 0\n",
    "            torch.save(model.state_dict(), checkpoint_file)\n",
    "            print(\"Saved model.\")\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            print(\"No improvement.\")\n",
    "            if no_improvement >= early_stopping:\n",
    "                print(f\"Early Stopping\")\n",
    "                break\n",
    "                \n",
    "                \n",
    "        # reduce learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "            \n",
    "                                              \n",
    "checkpoint_file = 'flair_vgg16_model_final.pt'      \n",
    "lr = 0.001\n",
    "epochs = 20         \n",
    "\n",
    "model = MyModel()\n",
    "#print(model)\n",
    "train_model(model, epochs, lr, train_df, val_df, checkpoint_file)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/850 correct. Accuracy: 69.52941176470588 %, acc 0.6952941176470588, f1 0.695199196981759\n"
     ]
    }
   ],
   "source": [
    "def eval_model(model, test_df):\n",
    "    if train_on_gpu:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    all_pred = np.array([])\n",
    "    all_labels = np.array([])\n",
    "    for i, (sentences, images, labels) in enumerate(get_batches(test_df, test_transform)):\n",
    "        if train_on_gpu:\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        out = model(sentences, images)\n",
    "        pred = torch.round(torch.sigmoid(out.squeeze()))\n",
    "\n",
    "        correct = (pred == labels)\n",
    "        correct = correct.cpu().numpy() if train_on_gpu else correct.numpy()        \n",
    "        num_correct += np.sum(correct)\n",
    "        num_total += labels.size(0)\n",
    "\n",
    "\n",
    "        \n",
    "        pred_np = pred.data.cpu().numpy() if train_on_gpu else pred.data.numpy()\n",
    "        labels_np = labels.data.cpu().numpy() if train_on_gpu else labels.data.numpy()                    \n",
    "        all_pred = np.concatenate([all_pred, pred_np])\n",
    "        all_labels = np.concatenate([all_labels, labels_np])\n",
    "        \n",
    "        \n",
    "        store_embeddings(sentences, 'cpu')\n",
    "\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_pred, average='weighted')\n",
    "    acc = accuracy_score(all_labels, all_pred)\n",
    "    \n",
    "    print(f\"{num_correct}/{num_total} correct. Accuracy: {num_correct*100/num_total} %, acc {acc}, f1 {f1}\")\n",
    "    \n",
    "    \n",
    "best_model = MyModel()\n",
    "best_model.load_state_dict(torch.load(checkpoint_file))\n",
    "eval_model(best_model, test_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:efficientnet]",
   "language": "python",
   "name": "conda-env-efficientnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
