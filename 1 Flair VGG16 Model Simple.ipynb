{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "published_count 2658\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>message</th>\n",
       "      <th>image_concept</th>\n",
       "      <th>published</th>\n",
       "      <th>disabled</th>\n",
       "      <th>available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e5836fee917e8d9a8a7b277</td>\n",
       "      <td>endless blues greatbarrierreef australia whits...</td>\n",
       "      <td>seascape water shoal sea turquoise sun tropica...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e58343ded065ad79e312f3d</td>\n",
       "      <td>hamiltonisland</td>\n",
       "      <td>tree travel vacation seashore water hotel isla...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e57dc939e88b6be2ac42800</td>\n",
       "      <td>we are going coconuts for hamiltonisland here ...</td>\n",
       "      <td>relaxation beach sea vacation sand recreation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e55dca437fa5927dcdf02f3</td>\n",
       "      <td>en route to gbr embrace the elevation in luxur...</td>\n",
       "      <td>nature travel diving water sea underwater ocea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e55d69eb9e5b725cd7ba02f</td>\n",
       "      <td>golf course views hamiltonislandgolfcourse whi...</td>\n",
       "      <td>outdoors landscape beach sky nature rural nope...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>5e3eb4abf0227ce8e168c7d4</td>\n",
       "      <td>insane bonuses with fm fast start bonuses up t...</td>\n",
       "      <td>car automobile vehicle transportation human pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>5e3ea825870465e4bf3a1deb</td>\n",
       "      <td>ciropicariello chibevefianovasanoevalontano gr...</td>\n",
       "      <td>apparel clothing water human person outdoors v...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>5e3ea823ee8283e4d618f6f4</td>\n",
       "      <td>ciropicariello chibevefianovasanoevalontano gr...</td>\n",
       "      <td>human person clothing apparel vessel transport...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314</th>\n",
       "      <td>5e3ea503ee8283e4d618f1fc</td>\n",
       "      <td>y u me bigfella 006 mrandmrsbond husbandandwif...</td>\n",
       "      <td>person face human smile female girl teen blond...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>5e3ea1a783445de2d905d67d</td>\n",
       "      <td>swim scubadive in the greatbarrierreef one of ...</td>\n",
       "      <td>water nature outdoors ocean sea land lake lago...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5316 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id  \\\n",
       "0     5e5836fee917e8d9a8a7b277   \n",
       "1     5e58343ded065ad79e312f3d   \n",
       "2     5e57dc939e88b6be2ac42800   \n",
       "3     5e55dca437fa5927dcdf02f3   \n",
       "4     5e55d69eb9e5b725cd7ba02f   \n",
       "...                        ...   \n",
       "5311  5e3eb4abf0227ce8e168c7d4   \n",
       "5312  5e3ea825870465e4bf3a1deb   \n",
       "5313  5e3ea823ee8283e4d618f6f4   \n",
       "5314  5e3ea503ee8283e4d618f1fc   \n",
       "5315  5e3ea1a783445de2d905d67d   \n",
       "\n",
       "                                                message  \\\n",
       "0     endless blues greatbarrierreef australia whits...   \n",
       "1                                        hamiltonisland   \n",
       "2     we are going coconuts for hamiltonisland here ...   \n",
       "3     en route to gbr embrace the elevation in luxur...   \n",
       "4     golf course views hamiltonislandgolfcourse whi...   \n",
       "...                                                 ...   \n",
       "5311  insane bonuses with fm fast start bonuses up t...   \n",
       "5312  ciropicariello chibevefianovasanoevalontano gr...   \n",
       "5313  ciropicariello chibevefianovasanoevalontano gr...   \n",
       "5314  y u me bigfella 006 mrandmrsbond husbandandwif...   \n",
       "5315  swim scubadive in the greatbarrierreef one of ...   \n",
       "\n",
       "                                          image_concept  published  disabled  \\\n",
       "0     seascape water shoal sea turquoise sun tropica...          1         0   \n",
       "1     tree travel vacation seashore water hotel isla...          1         0   \n",
       "2     relaxation beach sea vacation sand recreation ...          1         0   \n",
       "3     nature travel diving water sea underwater ocea...          1         0   \n",
       "4     outdoors landscape beach sky nature rural nope...          1         0   \n",
       "...                                                 ...        ...       ...   \n",
       "5311  car automobile vehicle transportation human pe...          0         1   \n",
       "5312  apparel clothing water human person outdoors v...          0         1   \n",
       "5313  human person clothing apparel vessel transport...          0         1   \n",
       "5314  person face human smile female girl teen blond...          0         1   \n",
       "5315  water nature outdoors ocean sea land lake lago...          0         1   \n",
       "\n",
       "      available  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "5311          1  \n",
       "5312          1  \n",
       "5313          1  \n",
       "5314          1  \n",
       "5315          1  \n",
       "\n",
       "[5316 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('flair-vgg16-data.csv', names=['_id', 'message', 'image_concept', 'published', 'disabled'])\n",
    "df['available'] = 0\n",
    "\n",
    "all_images_path = 'data/all_images'\n",
    "for i, row in df.iterrows():\n",
    "    if os.path.isfile(os.path.join(all_images_path, row['_id'] + '.jpg')):\n",
    "        df.at[i, 'available']= 1    \n",
    "        \n",
    "df_published = df.loc[df.query('available == 1 and published == 1').index]\n",
    "published_count = len(df_published)\n",
    "\n",
    "print(f'published_count {published_count}')\n",
    "df_disabled = df.loc[df.query('available == 1 and disabled == 1').index]\n",
    "df_disabled = df_disabled[:published_count]\n",
    "\n",
    "df_all = pd.concat([df_published, df_disabled], ignore_index=True)\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, validation_df = train_test_split(df_all, test_size=0.4, random_state=42)\n",
    "validation_df, test_df = train_test_split(validation_df, test_size=0.4, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df: 3189, published 1568\n",
      "val df: 1276, published 662\n",
      "test df: 851, published 428\n"
     ]
    }
   ],
   "source": [
    "print(f\"train df: {len(train_df)}, published {len(train_df.loc[train_df['published'] == 1])}\")\n",
    "\n",
    "print(f\"val df: {len(validation_df)}, published {len(validation_df.loc[validation_df['published'] == 1])}\")\n",
    "\n",
    "print(f\"test df: {len(test_df)}, published {len(test_df.loc[test_df['published'] == 1])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple(\n",
      "  (fc1): Linear(in_features=29284, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (sig): Sigmoid()\n",
      ")\n",
      "Epoch 0, Batch 0, train loss 0.049432702362537384\n",
      "Epoch 0, Batch 100, train loss 0.055464982986450195\n",
      "> Epoch 0, train loss 0.04782920747799124\n",
      "> Epoch 0, val loss 0.0419798557147337\n",
      "Saved model.\n",
      "Epoch 1, Batch 0, train loss 0.04510163143277168\n",
      "Epoch 1, Batch 100, train loss 0.04410645738244057\n",
      "> Epoch 1, train loss 0.03275674217526312\n",
      "> Epoch 1, val loss 0.04148116056167967\n",
      "Saved model.\n",
      "Epoch 2, Batch 0, train loss 0.021382298320531845\n",
      "Epoch 2, Batch 100, train loss 0.021304506808519363\n",
      "> Epoch 2, train loss 0.027314025888849704\n",
      "> Epoch 2, val loss 0.04057943519660298\n",
      "Saved model.\n",
      "Epoch 3, Batch 0, train loss 0.023289240896701813\n",
      "Epoch 3, Batch 100, train loss 0.03841153532266617\n",
      "> Epoch 3, train loss 0.022103662986054845\n",
      "> Epoch 3, val loss 0.04133205258267053\n",
      "No improvement.\n",
      "Epoch 4, Batch 0, train loss 0.0075067440047860146\n",
      "Epoch 4, Batch 100, train loss 0.030643057078123093\n",
      "> Epoch 4, train loss 0.018709301317736213\n",
      "> Epoch 4, val loss 0.041219689816143074\n",
      "No improvement.\n",
      "Epoch 5, Batch 0, train loss 0.01851174421608448\n",
      "Epoch 5, Batch 100, train loss 0.021616999059915543\n",
      "> Epoch 5, train loss 0.016144503025976458\n",
      "> Epoch 5, val loss 0.04197586877826239\n",
      "No improvement.\n",
      "Epoch 6, Batch 0, train loss 0.01694556698203087\n",
      "Epoch 6, Batch 100, train loss 0.01090987864881754\n",
      "> Epoch 6, train loss 0.014525086689926157\n",
      "> Epoch 6, val loss 0.04163290493680766\n",
      "No improvement.\n",
      "Epoch 7, Batch 0, train loss 0.014077945612370968\n",
      "Epoch 7, Batch 100, train loss 0.005813813768327236\n",
      "> Epoch 7, train loss 0.013281741836912844\n",
      "> Epoch 7, val loss 0.043144483971745244\n",
      "No improvement.\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, id_to_text_features, id_to_image_features):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.id_to_text_features = id_to_text_features\n",
    "        self.id_to_image_features = id_to_image_features\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        _id = self.df.loc[index]['_id']\n",
    "        label = 1 if self.df.loc[index]['published'] else 0\n",
    "        text_features = self.id_to_text_features[_id]\n",
    "        image_features = self.id_to_image_features[_id]\n",
    "        \n",
    "        features = np.concatenate([text_features, image_features])\n",
    "        \n",
    "        return features, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "\n",
    "id_to_image_features_file = 'flair_vgg16_image_features.pkl'\n",
    "id_to_text_features_file = 'flair_vgg16_text_features_twitter.pkl'\n",
    "id_to_image_features = None\n",
    "id_to_text_features = None\n",
    "with open(id_to_image_features_file, 'rb') as f:\n",
    "    id_to_image_features = pickle.load(f)    \n",
    "with open(id_to_text_features_file, 'rb') as f:\n",
    "    id_to_text_features = pickle.load(f)\n",
    "\n",
    "\n",
    "        \n",
    "batch_size = 16\n",
    "train_dataset = MyDataset(train_df, id_to_text_features, id_to_image_features)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = MyDataset(validation_df, id_to_text_features, id_to_image_features)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True )\n",
    "\n",
    "test_dataset = MyDataset(test_df, id_to_text_features, id_to_image_features)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True )\n",
    "\n",
    "                    \n",
    "class Simple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(29284, 1)\n",
    "        #self.fc2 = nn.Linear(4096, 1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "        nn.init.xavier_uniform(self.fc1.weight)\n",
    "        #nn.init.xavier_uniform(self.fc2.weight)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)        \n",
    "        x = self.sig(self.fc1(x))        \n",
    "#         x = self.dropout(x)        \n",
    "#         x = self.sig(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "def train_model(model, epochs, lr, train_dataloader, val_dataloader, checkpoint_file, early_stopping=5,):        \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_loss = np.inf\n",
    "    no_improvement = 0\n",
    "\n",
    "    if train_on_gpu:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    for epoch in range(epochs):        \n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        # Train\n",
    "        model.train()        \n",
    "        for i, (features, labels) in enumerate(train_dataloader):\n",
    "            if train_on_gpu:\n",
    "                features, labels = features.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = model(features)\n",
    "            loss = criterion(out.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Batch {i}, train loss {loss.item()/labels.size(0)}\")\n",
    "            \n",
    "            \n",
    "        train_loss = total_train_loss/len(train_dataloader.dataset)\n",
    "        print(f\"> Epoch {epoch}, train loss {train_loss}\")\n",
    "        \n",
    "        # Eval\n",
    "        model.eval()\n",
    "        for features, labels in val_dataloader:\n",
    "            if train_on_gpu:\n",
    "                features, labels = features.cuda(), labels.cuda()\n",
    "                \n",
    "            out = model(features)\n",
    "            loss = criterion(out.squeeze(), labels.float())\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            \n",
    "        val_loss = total_val_loss / len(val_dataloader.dataset)\n",
    "        \n",
    "        print(f\"> Epoch {epoch}, val loss {val_loss}\")\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            no_improvement = 0\n",
    "            torch.save(model.state_dict(), checkpoint_file)\n",
    "            print(\"Saved model.\")\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            print(\"No improvement.\")\n",
    "            if no_improvement >= early_stopping:\n",
    "                print(f\"Early Stopping\")\n",
    "                break\n",
    "            \n",
    "                                              \n",
    "checkpoint_file = 'flair_vgg16_simple.pt'      \n",
    "lr = 0.0001\n",
    "epochs = 100            \n",
    "model = Simple()\n",
    "print(model)\n",
    "\n",
    "train_model(model, epochs, lr, train_dataloader, val_dataloader, checkpoint_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/851 correct. Accuracy: 71.09283196239718 %\n"
     ]
    }
   ],
   "source": [
    "def eval_model(model, test_dataloader):\n",
    "    if train_on_gpu:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    for i, (features, labels) in enumerate(test_dataloader):\n",
    "        if train_on_gpu:\n",
    "            features, labels = features.cuda(), labels.cuda()\n",
    "            \n",
    "        out = model(features)\n",
    "        pred = torch.round(out.squeeze())\n",
    "        correct = (pred == labels)\n",
    "        correct = correct.cpu().numpy() if train_on_gpu else correct.numpy()\n",
    "        \n",
    "        num_correct += np.sum(correct)\n",
    "        \n",
    "    total = len(test_dataloader.dataset)\n",
    "    print(f\"{num_correct}/{total} correct. Accuracy: {num_correct*100/total} %\")\n",
    "    \n",
    "    \n",
    "best_model = Simple()\n",
    "best_model.load_state_dict(torch.load(checkpoint_file))\n",
    "eval_model(best_model, test_dataloader)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:efficientnet]",
   "language": "python",
   "name": "conda-env-efficientnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
