{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>message</th>\n",
       "      <th>image_concept</th>\n",
       "      <th>published</th>\n",
       "      <th>disabled</th>\n",
       "      <th>available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e5836fee917e8d9a8a7b277</td>\n",
       "      <td>endless blues greatbarrierreef australia whits...</td>\n",
       "      <td>seascape water shoal sea turquoise sun tropica...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e58343ded065ad79e312f3d</td>\n",
       "      <td>hamiltonisland</td>\n",
       "      <td>tree travel vacation seashore water hotel isla...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e57dc939e88b6be2ac42800</td>\n",
       "      <td>we are going coconuts for hamiltonisland here ...</td>\n",
       "      <td>relaxation beach sea vacation sand recreation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e55dca437fa5927dcdf02f3</td>\n",
       "      <td>en route to gbr embrace the elevation in luxur...</td>\n",
       "      <td>nature travel diving water sea underwater ocea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e55d69eb9e5b725cd7ba02f</td>\n",
       "      <td>golf course views hamiltonislandgolfcourse whi...</td>\n",
       "      <td>outdoors landscape beach sky nature rural nope...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8052</th>\n",
       "      <td>5e253779f1b8d48ba5de7d32</td>\n",
       "      <td>colours so bright they hurt your eyes tropical...</td>\n",
       "      <td>outdoors nature scenery landscape water land o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>5e252d334610948976f731e5</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>human person patient therapy massage heel spa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>5e252d334610948976f731e6</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>plant paper text flower blossom</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8055</th>\n",
       "      <td>5e252d3342307c89757703c0</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>person human finger hand dating face arm</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8056</th>\n",
       "      <td>5e252d33f7b8d8898b9e841f</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>human person patient massage therapy spa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8057 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id  \\\n",
       "0     5e5836fee917e8d9a8a7b277   \n",
       "1     5e58343ded065ad79e312f3d   \n",
       "2     5e57dc939e88b6be2ac42800   \n",
       "3     5e55dca437fa5927dcdf02f3   \n",
       "4     5e55d69eb9e5b725cd7ba02f   \n",
       "...                        ...   \n",
       "8052  5e253779f1b8d48ba5de7d32   \n",
       "8053  5e252d334610948976f731e5   \n",
       "8054  5e252d334610948976f731e6   \n",
       "8055  5e252d3342307c89757703c0   \n",
       "8056  5e252d33f7b8d8898b9e841f   \n",
       "\n",
       "                                                message  \\\n",
       "0     endless blues greatbarrierreef australia whits...   \n",
       "1                                        hamiltonisland   \n",
       "2     we are going coconuts for hamiltonisland here ...   \n",
       "3     en route to gbr embrace the elevation in luxur...   \n",
       "4     golf course views hamiltonislandgolfcourse whi...   \n",
       "...                                                 ...   \n",
       "8052  colours so bright they hurt your eyes tropical...   \n",
       "8053  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "8054  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "8055  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "8056  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "\n",
       "                                          image_concept  published  disabled  \\\n",
       "0     seascape water shoal sea turquoise sun tropica...          1         0   \n",
       "1     tree travel vacation seashore water hotel isla...          1         0   \n",
       "2     relaxation beach sea vacation sand recreation ...          1         0   \n",
       "3     nature travel diving water sea underwater ocea...          1         0   \n",
       "4     outdoors landscape beach sky nature rural nope...          1         0   \n",
       "...                                                 ...        ...       ...   \n",
       "8052  outdoors nature scenery landscape water land o...          0         1   \n",
       "8053      human person patient therapy massage heel spa          0         1   \n",
       "8054                    plant paper text flower blossom          0         1   \n",
       "8055           person human finger hand dating face arm          0         1   \n",
       "8056           human person patient massage therapy spa          0         1   \n",
       "\n",
       "      available  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "8052          1  \n",
       "8053          1  \n",
       "8054          1  \n",
       "8055          1  \n",
       "8056          1  \n",
       "\n",
       "[8057 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('flair-vgg16-data.csv', names=['_id', 'message', 'image_concept', 'published', 'disabled'])\n",
    "df['available'] = 0\n",
    "\n",
    "all_images_path = 'data/all_images'\n",
    "for i, row in df.iterrows():\n",
    "    if os.path.isfile(os.path.join(all_images_path, row['_id'] + '.jpg')):\n",
    "        df.at[i, 'available']= 1    \n",
    "        \n",
    "df_published = df.loc[df.query('available == 1 and published == 1').index]\n",
    "df_disabled = df.loc[df.query('available == 1 and disabled == 1').index]\n",
    "\n",
    "df_all = pd.concat([df_published, df_disabled], ignore_index=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, validation_df = train_test_split(df_all, test_size=0.4, random_state=42)\n",
    "validation_df, test_df = train_test_split(validation_df, test_size=0.4, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df: 4834, published 1580\n",
      "val df: 1933, published 647\n",
      "test df: 1290, published 431\n"
     ]
    }
   ],
   "source": [
    "print(f\"train df: {len(train_df)}, published {len(train_df.loc[train_df['published'] == 1])}\")\n",
    "\n",
    "print(f\"val df: {len(validation_df)}, published {len(validation_df.loc[validation_df['published'] == 1])}\")\n",
    "\n",
    "print(f\"test df: {len(test_df)}, published {len(test_df.loc[test_df['published'] == 1])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple(\n",
      "  (fc1): Linear(in_features=29284, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (sig): Sigmoid()\n",
      ")\n",
      "Epoch 0, Batch 0, train loss 0.05642422288656235\n",
      "Epoch 0, Batch 100, train loss 0.053428493440151215\n",
      "Epoch 0, Batch 200, train loss 0.06526434421539307\n",
      "Epoch 0, Batch 300, train loss 0.04304591938853264\n",
      "> Epoch 0, train loss 0.04537547463886393\n",
      "> Epoch 0, val loss 0.03918850165972485\n",
      "Saved model.\n",
      "Epoch 1, Batch 0, train loss 0.03552984818816185\n",
      "Epoch 1, Batch 100, train loss 0.015599235892295837\n",
      "Epoch 1, Batch 200, train loss 0.02722085639834404\n",
      "Epoch 1, Batch 300, train loss 0.030021648854017258\n",
      "> Epoch 1, train loss 0.03623483657997208\n",
      "> Epoch 1, val loss 0.03765777837286573\n",
      "Saved model.\n",
      "Epoch 2, Batch 0, train loss 0.024481691420078278\n",
      "Epoch 2, Batch 100, train loss 0.017380662262439728\n",
      "Epoch 2, Batch 200, train loss 0.019952483475208282\n",
      "Epoch 2, Batch 300, train loss 0.040174953639507294\n",
      "> Epoch 2, train loss 0.030815064604981752\n",
      "> Epoch 2, val loss 0.03654268889678801\n",
      "Saved model.\n",
      "Epoch 3, Batch 0, train loss 0.039373718202114105\n",
      "Epoch 3, Batch 100, train loss 0.024532072246074677\n",
      "Epoch 3, Batch 200, train loss 0.022712457925081253\n",
      "Epoch 3, Batch 300, train loss 0.03870861977338791\n",
      "> Epoch 3, train loss 0.026596737577031602\n",
      "> Epoch 3, val loss 0.03664549603958051\n",
      "No improvement.\n",
      "Epoch 4, Batch 0, train loss 0.05564974620938301\n",
      "Epoch 4, Batch 100, train loss 0.03808651119470596\n",
      "Epoch 4, Batch 200, train loss 0.032171864062547684\n",
      "Epoch 4, Batch 300, train loss 0.03388170525431633\n",
      "> Epoch 4, train loss 0.023982486449086474\n",
      "> Epoch 4, val loss 0.03724230406926323\n",
      "No improvement.\n",
      "Epoch 5, Batch 0, train loss 0.02338220551609993\n",
      "Epoch 5, Batch 100, train loss 0.009506991133093834\n",
      "Epoch 5, Batch 200, train loss 0.02180122584104538\n",
      "Epoch 5, Batch 300, train loss 0.028083866462111473\n",
      "> Epoch 5, train loss 0.022127772131561\n",
      "> Epoch 5, val loss 0.03611528457166985\n",
      "Saved model.\n",
      "Epoch 6, Batch 0, train loss 0.0168362557888031\n",
      "Epoch 6, Batch 100, train loss 0.013771381229162216\n",
      "Epoch 6, Batch 200, train loss 0.012644490227103233\n",
      "Epoch 6, Batch 300, train loss 0.016339043155312538\n",
      "> Epoch 6, train loss 0.020175315043590363\n",
      "> Epoch 6, val loss 0.036311859140665\n",
      "No improvement.\n",
      "Epoch 7, Batch 0, train loss 0.02142258919775486\n",
      "Epoch 7, Batch 100, train loss 0.018102997913956642\n",
      "Epoch 7, Batch 200, train loss 0.021832268685102463\n",
      "Epoch 7, Batch 300, train loss 0.0188630148768425\n",
      "> Epoch 7, train loss 0.018436176803334467\n",
      "> Epoch 7, val loss 0.03701862840842411\n",
      "No improvement.\n",
      "Epoch 8, Batch 0, train loss 0.018714353442192078\n",
      "Epoch 8, Batch 100, train loss 0.018326111137866974\n",
      "Epoch 8, Batch 200, train loss 0.018872110173106194\n",
      "Epoch 8, Batch 300, train loss 0.01170019805431366\n",
      "> Epoch 8, train loss 0.017369000257343906\n",
      "> Epoch 8, val loss 0.03633493787102667\n",
      "No improvement.\n",
      "Epoch 9, Batch 0, train loss 0.01288190484046936\n",
      "Epoch 9, Batch 100, train loss 0.01191467884927988\n",
      "Epoch 9, Batch 200, train loss 0.02112392522394657\n",
      "Epoch 9, Batch 300, train loss 0.008077843114733696\n",
      "> Epoch 9, train loss 0.015996221036803985\n",
      "> Epoch 9, val loss 0.037058388745914266\n",
      "No improvement.\n",
      "Epoch 10, Batch 0, train loss 0.01836356148123741\n",
      "Epoch 10, Batch 100, train loss 0.006527590565383434\n",
      "Epoch 10, Batch 200, train loss 0.008273102343082428\n",
      "Epoch 10, Batch 300, train loss 0.012175807729363441\n",
      "> Epoch 10, train loss 0.015131942730552655\n",
      "> Epoch 10, val loss 0.03723835734678437\n",
      "No improvement.\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, id_to_text_features, id_to_image_features):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.id_to_text_features = id_to_text_features\n",
    "        self.id_to_image_features = id_to_image_features\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        _id = self.df.loc[index]['_id']\n",
    "        label = 1 if self.df.loc[index]['published'] else 0\n",
    "        text_features = self.id_to_text_features[_id]\n",
    "        image_features = self.id_to_image_features[_id]\n",
    "        \n",
    "        features = np.concatenate([text_features, image_features])\n",
    "        \n",
    "        return features, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "\n",
    "id_to_image_features_file = 'flair_vgg16_image_features.pkl'\n",
    "id_to_text_features_file = 'flair_vgg16_text_features_twitter.pkl'\n",
    "id_to_image_features = None\n",
    "id_to_text_features = None\n",
    "with open(id_to_image_features_file, 'rb') as f:\n",
    "    id_to_image_features = pickle.load(f)    \n",
    "with open(id_to_text_features_file, 'rb') as f:\n",
    "    id_to_text_features = pickle.load(f)\n",
    "\n",
    "\n",
    "        \n",
    "batch_size = 16\n",
    "train_dataset = MyDataset(train_df, id_to_text_features, id_to_image_features)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = MyDataset(validation_df, id_to_text_features, id_to_image_features)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True )\n",
    "\n",
    "test_dataset = MyDataset(test_df, id_to_text_features, id_to_image_features)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True )\n",
    "\n",
    "                    \n",
    "class Simple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(29284, 1)\n",
    "        #self.fc2 = nn.Linear(4096, 1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "        nn.init.xavier_uniform(self.fc1.weight)\n",
    "        #nn.init.xavier_uniform(self.fc2.weight)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)        \n",
    "        x = self.sig(self.fc1(x))        \n",
    "#         x = self.dropout(x)        \n",
    "#         x = self.sig(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "def train_model(model, epochs, lr, train_dataloader, val_dataloader, checkpoint_file, early_stopping=5,):        \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_loss = np.inf\n",
    "    no_improvement = 0\n",
    "\n",
    "    if train_on_gpu:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    for epoch in range(epochs):        \n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        # Train\n",
    "        model.train()        \n",
    "        for i, (features, labels) in enumerate(train_dataloader):\n",
    "            if train_on_gpu:\n",
    "                features, labels = features.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = model(features)\n",
    "            loss = criterion(out.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Batch {i}, train loss {loss.item()/labels.size(0)}\")\n",
    "            \n",
    "            \n",
    "        train_loss = total_train_loss/len(train_dataloader.dataset)\n",
    "        print(f\"> Epoch {epoch}, train loss {train_loss}\")\n",
    "        \n",
    "        # Eval\n",
    "        model.eval()\n",
    "        for features, labels in val_dataloader:\n",
    "            if train_on_gpu:\n",
    "                features, labels = features.cuda(), labels.cuda()\n",
    "                \n",
    "            out = model(features)\n",
    "            loss = criterion(out.squeeze(), labels.float())\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            \n",
    "        val_loss = total_val_loss / len(val_dataloader.dataset)\n",
    "        \n",
    "        print(f\"> Epoch {epoch}, val loss {val_loss}\")\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            no_improvement = 0\n",
    "            torch.save(model.state_dict(), checkpoint_file)\n",
    "            print(\"Saved model.\")\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            print(\"No improvement.\")\n",
    "            if no_improvement >= early_stopping:\n",
    "                print(f\"Early Stopping\")\n",
    "                break\n",
    "            \n",
    "                                              \n",
    "checkpoint_file = 'flair_vgg16_simple.pt'      \n",
    "lr = 0.00005\n",
    "epochs = 100            \n",
    "model = Simple()\n",
    "print(model)\n",
    "\n",
    "train_model(model, epochs, lr, train_dataloader, val_dataloader, checkpoint_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/1290 correct. Accuracy: 72.55813953488372 %\n"
     ]
    }
   ],
   "source": [
    "def eval_model(model, test_dataloader):\n",
    "    if train_on_gpu:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    for i, (features, labels) in enumerate(test_dataloader):\n",
    "        if train_on_gpu:\n",
    "            features, labels = features.cuda(), labels.cuda()\n",
    "            \n",
    "        out = model(features)\n",
    "        pred = torch.round(out.squeeze())\n",
    "        correct = (pred == labels)\n",
    "        correct = correct.cpu().numpy() if train_on_gpu else correct.numpy()\n",
    "        \n",
    "        num_correct += np.sum(correct)\n",
    "        \n",
    "    total = len(test_dataloader.dataset)\n",
    "    print(f\"{num_correct}/{total} correct. Accuracy: {num_correct*100/total} %\")\n",
    "    \n",
    "    \n",
    "best_model = Simple()\n",
    "best_model.load_state_dict(torch.load(checkpoint_file))\n",
    "eval_model(best_model, test_dataloader)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:efficientnet]",
   "language": "python",
   "name": "conda-env-efficientnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
