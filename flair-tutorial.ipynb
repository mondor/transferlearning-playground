{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence, segtok_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"the grass is green .\" - 5 Tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Token: 4 green"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = Sentence(\"the grass is green.\", use_tokenizer=True)\n",
    "print(sentence)\n",
    "sentence.get_token(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"the grass is green .\" - 5 Tokens\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence(\"the grass is green.\", use_tokenizer=segtok_tokenizer)\n",
    "print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the grass is green <color> .\n",
      "Token: 4 green value of color score 1.0 \n"
     ]
    }
   ],
   "source": [
    "sentence[3].add_tag('ner', 'color')\n",
    "print(sentence.to_tagged_string())\n",
    "token = sentence[3]\n",
    "tag = token.get_tag('ner')\n",
    "print(f'{token} value of {tag.value} score {tag.score} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence(\"Frane is the current world cup winner.\")\n",
    "sentence.add_labels(['sports', 'world cup'])\n",
    "sentence = Sentence(\"Frane is the current world cup winner.\", labels=['sports', 'world cup'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 02:54:33,089 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/NER-conll03-english/en-ner-conll03-v0.4.pt not found in cache, downloading to /tmp/tmp78dx6yqo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432197603/432197603 [00:44<00:00, 9684465.17B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 02:55:18,435 copying /tmp/tmp78dx6yqo to cache at /home/ec2-user/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 02:55:18,831 removing temp file /tmp/tmp78dx6yqo\n",
      "2020-03-26 02:55:18,884 loading file /home/ec2-user/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "tagger = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George <B-PER> Gershwin <E-PER> is a musical genius.\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('George Gershwin is a musical genius.')\n",
    "tagger.predict(sentence)\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER-span [1,2]: \"George Gershwin\"\n"
     ]
    }
   ],
   "source": [
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'George Gershwin is a musical genius.', 'labels': [], 'entities': [{'text': 'George Gershwin', 'start_pos': 0, 'end_pos': 15, 'type': 'PER', 'confidence': 0.9973272085189819}]}\n"
     ]
    }
   ],
   "source": [
    "print(sentence.to_dict(tag_type='ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 03:02:42,317 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/classy-imdb-en-rnn-cuda%3A0/imdb-v0.4.pt not found in cache, downloading to /tmp/tmp_n2q4bmw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501979561/1501979561 [02:39<00:00, 9389535.92B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 03:05:23,051 copying /tmp/tmp_n2q4bmw to cache at /home/ec2-user/.flair/models/imdb-v0.4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 03:05:24,384 removing temp file /tmp/tmp_n2q4bmw\n",
      "2020-03-26 03:05:24,563 loading file /home/ec2-user/.flair/models/imdb-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "classifier = TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NEGATIVE (0.9146466851234436)]\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"To the government’s immense credit, unlike with climate change, it appears to be acting on scientific advice. And given that one of Scott Morrison’s favoured political allies, Donald Trump, is advocating getting the US back to work by Easter and using the coronavirus to stoke xenophobia, that is no small thing for which we should be very grateful. But what is clear is that Morrison is also doing his level best to keep us all confused. Tuesday night’s press conference was the prime minister at his bumbling, inept worst.\"\"\"\n",
    "sentence = Sentence(txt)\n",
    "\n",
    "classifier.predict(sentence)\n",
    "print(sentence.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 03:09:53,907 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpsa9bgx1n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160000128/160000128 [00:18<00:00, 8719353.98B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 03:10:13,005 copying /tmp/tmpsa9bgx1n to cache at /home/ec2-user/.flair/embeddings/glove.gensim.vectors.npy\n",
      "2020-03-26 03:10:13,151 removing temp file /tmp/tmpsa9bgx1n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 03:10:13,880 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmpig0h1nve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21494764/21494764 [00:02<00:00, 7187307.64B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 03:10:17,608 copying /tmp/tmpig0h1nve to cache at /home/ec2-user/.flair/embeddings/glove.gensim\n",
      "2020-03-26 03:10:17,633 removing temp file /tmp/tmpig0h1nve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "glove_embedding = WordEmbeddings('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.8970e-01,  5.0024e-02,  1.9084e-01, -4.9184e-02, -8.9737e-02,\n",
      "         2.1006e-01, -5.4952e-01,  9.8377e-02, -2.0135e-01,  3.4241e-01,\n",
      "        -9.2677e-02,  1.6100e-01, -1.3268e-01, -2.8160e-01,  1.8737e-01,\n",
      "        -4.2959e-01,  9.6039e-01,  1.3972e-01, -1.0781e+00,  4.0518e-01,\n",
      "         5.0539e-01, -5.5064e-01,  4.8440e-01,  3.8044e-01, -2.9055e-03,\n",
      "        -3.4942e-01, -9.9696e-02, -7.8368e-01,  1.0363e+00, -2.3140e-01,\n",
      "        -4.7121e-01,  5.7126e-01, -2.1454e-01,  3.5958e-01, -4.8319e-01,\n",
      "         1.0875e+00,  2.8524e-01,  1.2447e-01, -3.9248e-02, -7.6732e-02,\n",
      "        -7.6343e-01, -3.2409e-01, -5.7490e-01, -1.0893e+00, -4.1811e-01,\n",
      "         4.5120e-01,  1.2112e-01, -5.1367e-01, -1.3349e-01, -1.1378e+00,\n",
      "        -2.8768e-01,  1.6774e-01,  5.5804e-01,  1.5387e+00,  1.8859e-02,\n",
      "        -2.9721e+00, -2.4216e-01, -9.2495e-01,  2.1992e+00,  2.8234e-01,\n",
      "        -3.4780e-01,  5.1621e-01, -4.3387e-01,  3.6852e-01,  7.4573e-01,\n",
      "         7.2102e-02,  2.7931e-01,  9.2569e-01, -5.0336e-02, -8.5856e-01,\n",
      "        -1.3580e-01, -9.2551e-01, -3.3991e-01, -1.0394e+00, -6.7203e-02,\n",
      "        -2.1379e-01, -4.7690e-01,  2.1377e-01, -8.4008e-01,  5.2536e-02,\n",
      "         5.9298e-01,  2.9604e-01, -6.7644e-01,  1.3916e-01, -1.5504e+00,\n",
      "        -2.0765e-01,  7.2220e-01,  5.2056e-01, -7.6221e-02, -1.5194e-01,\n",
      "        -1.3134e-01,  5.8617e-02, -3.1869e-01, -6.1419e-01, -6.2393e-01,\n",
      "        -4.1548e-01, -3.8175e-02, -3.9804e-01,  4.7647e-01, -1.5983e-01],\n",
      "       device='cuda:0')\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence(txt)\n",
    "glove_embedding.embed(sentence)b\n",
    "for token in sentence:\n",
    "    embedding = token.embedding\n",
    "    print(embedding)\n",
    "    print(embedding.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 To\n",
      "torch.Size([2048])\n",
      "Token: 2 the\n",
      "torch.Size([2048])\n",
      "Token: 3 government’s\n",
      "torch.Size([2048])\n",
      "Token: 4 immense\n",
      "torch.Size([2048])\n",
      "Token: 5 credit,\n",
      "torch.Size([2048])\n",
      "Token: 6 unlike\n",
      "torch.Size([2048])\n",
      "Token: 7 with\n",
      "torch.Size([2048])\n",
      "Token: 8 climate\n",
      "torch.Size([2048])\n",
      "Token: 9 change,\n",
      "torch.Size([2048])\n",
      "Token: 10 it\n",
      "torch.Size([2048])\n",
      "Token: 11 appears\n",
      "torch.Size([2048])\n",
      "Token: 12 to\n",
      "torch.Size([2048])\n",
      "Token: 13 be\n",
      "torch.Size([2048])\n",
      "Token: 14 acting\n",
      "torch.Size([2048])\n",
      "Token: 15 on\n",
      "torch.Size([2048])\n",
      "Token: 16 scientific\n",
      "torch.Size([2048])\n",
      "Token: 17 advice.\n",
      "torch.Size([2048])\n",
      "Token: 18 And\n",
      "torch.Size([2048])\n",
      "Token: 19 given\n",
      "torch.Size([2048])\n",
      "Token: 20 that\n",
      "torch.Size([2048])\n",
      "Token: 21 one\n",
      "torch.Size([2048])\n",
      "Token: 22 of\n",
      "torch.Size([2048])\n",
      "Token: 23 Scott\n",
      "torch.Size([2048])\n",
      "Token: 24 Morrison’s\n",
      "torch.Size([2048])\n",
      "Token: 25 favoured\n",
      "torch.Size([2048])\n",
      "Token: 26 political\n",
      "torch.Size([2048])\n",
      "Token: 27 allies,\n",
      "torch.Size([2048])\n",
      "Token: 28 Donald\n",
      "torch.Size([2048])\n",
      "Token: 29 Trump,\n",
      "torch.Size([2048])\n",
      "Token: 30 is\n",
      "torch.Size([2048])\n",
      "Token: 31 advocating\n",
      "torch.Size([2048])\n",
      "Token: 32 getting\n",
      "torch.Size([2048])\n",
      "Token: 33 the\n",
      "torch.Size([2048])\n",
      "Token: 34 US\n",
      "torch.Size([2048])\n",
      "Token: 35 back\n",
      "torch.Size([2048])\n",
      "Token: 36 to\n",
      "torch.Size([2048])\n",
      "Token: 37 work\n",
      "torch.Size([2048])\n",
      "Token: 38 by\n",
      "torch.Size([2048])\n",
      "Token: 39 Easter\n",
      "torch.Size([2048])\n",
      "Token: 40 and\n",
      "torch.Size([2048])\n",
      "Token: 41 using\n",
      "torch.Size([2048])\n",
      "Token: 42 the\n",
      "torch.Size([2048])\n",
      "Token: 43 coronavirus\n",
      "torch.Size([2048])\n",
      "Token: 44 to\n",
      "torch.Size([2048])\n",
      "Token: 45 stoke\n",
      "torch.Size([2048])\n",
      "Token: 46 xenophobia,\n",
      "torch.Size([2048])\n",
      "Token: 47 that\n",
      "torch.Size([2048])\n",
      "Token: 48 is\n",
      "torch.Size([2048])\n",
      "Token: 49 no\n",
      "torch.Size([2048])\n",
      "Token: 50 small\n",
      "torch.Size([2048])\n",
      "Token: 51 thing\n",
      "torch.Size([2048])\n",
      "Token: 52 for\n",
      "torch.Size([2048])\n",
      "Token: 53 which\n",
      "torch.Size([2048])\n",
      "Token: 54 we\n",
      "torch.Size([2048])\n",
      "Token: 55 should\n",
      "torch.Size([2048])\n",
      "Token: 56 be\n",
      "torch.Size([2048])\n",
      "Token: 57 very\n",
      "torch.Size([2048])\n",
      "Token: 58 grateful.\n",
      "torch.Size([2048])\n",
      "Token: 59 But\n",
      "torch.Size([2048])\n",
      "Token: 60 what\n",
      "torch.Size([2048])\n",
      "Token: 61 is\n",
      "torch.Size([2048])\n",
      "Token: 62 clear\n",
      "torch.Size([2048])\n",
      "Token: 63 is\n",
      "torch.Size([2048])\n",
      "Token: 64 that\n",
      "torch.Size([2048])\n",
      "Token: 65 Morrison\n",
      "torch.Size([2048])\n",
      "Token: 66 is\n",
      "torch.Size([2048])\n",
      "Token: 67 also\n",
      "torch.Size([2048])\n",
      "Token: 68 doing\n",
      "torch.Size([2048])\n",
      "Token: 69 his\n",
      "torch.Size([2048])\n",
      "Token: 70 level\n",
      "torch.Size([2048])\n",
      "Token: 71 best\n",
      "torch.Size([2048])\n",
      "Token: 72 to\n",
      "torch.Size([2048])\n",
      "Token: 73 keep\n",
      "torch.Size([2048])\n",
      "Token: 74 us\n",
      "torch.Size([2048])\n",
      "Token: 75 all\n",
      "torch.Size([2048])\n",
      "Token: 76 confused.\n",
      "torch.Size([2048])\n",
      "Token: 77 Tuesday\n",
      "torch.Size([2048])\n",
      "Token: 78 night’s\n",
      "torch.Size([2048])\n",
      "Token: 79 press\n",
      "torch.Size([2048])\n",
      "Token: 80 conference\n",
      "torch.Size([2048])\n",
      "Token: 81 was\n",
      "torch.Size([2048])\n",
      "Token: 82 the\n",
      "torch.Size([2048])\n",
      "Token: 83 prime\n",
      "torch.Size([2048])\n",
      "Token: 84 minister\n",
      "torch.Size([2048])\n",
      "Token: 85 at\n",
      "torch.Size([2048])\n",
      "Token: 86 his\n",
      "torch.Size([2048])\n",
      "Token: 87 bumbling,\n",
      "torch.Size([2048])\n",
      "Token: 88 inept\n",
      "torch.Size([2048])\n",
      "Token: 89 worst.\n",
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import FlairEmbeddings\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "sentence = Sentence(txt)\n",
    "flair_embedding_forward.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 To\n",
      "torch.Size([4196])\n",
      "Token: 2 the\n",
      "torch.Size([4196])\n",
      "Token: 3 government’s\n",
      "torch.Size([4196])\n",
      "Token: 4 immense\n",
      "torch.Size([4196])\n",
      "Token: 5 credit,\n",
      "torch.Size([4196])\n",
      "Token: 6 unlike\n",
      "torch.Size([4196])\n",
      "Token: 7 with\n",
      "torch.Size([4196])\n",
      "Token: 8 climate\n",
      "torch.Size([4196])\n",
      "Token: 9 change,\n",
      "torch.Size([4196])\n",
      "Token: 10 it\n",
      "torch.Size([4196])\n",
      "Token: 11 appears\n",
      "torch.Size([4196])\n",
      "Token: 12 to\n",
      "torch.Size([4196])\n",
      "Token: 13 be\n",
      "torch.Size([4196])\n",
      "Token: 14 acting\n",
      "torch.Size([4196])\n",
      "Token: 15 on\n",
      "torch.Size([4196])\n",
      "Token: 16 scientific\n",
      "torch.Size([4196])\n",
      "Token: 17 advice.\n",
      "torch.Size([4196])\n",
      "Token: 18 And\n",
      "torch.Size([4196])\n",
      "Token: 19 given\n",
      "torch.Size([4196])\n",
      "Token: 20 that\n",
      "torch.Size([4196])\n",
      "Token: 21 one\n",
      "torch.Size([4196])\n",
      "Token: 22 of\n",
      "torch.Size([4196])\n",
      "Token: 23 Scott\n",
      "torch.Size([4196])\n",
      "Token: 24 Morrison’s\n",
      "torch.Size([4196])\n",
      "Token: 25 favoured\n",
      "torch.Size([4196])\n",
      "Token: 26 political\n",
      "torch.Size([4196])\n",
      "Token: 27 allies,\n",
      "torch.Size([4196])\n",
      "Token: 28 Donald\n",
      "torch.Size([4196])\n",
      "Token: 29 Trump,\n",
      "torch.Size([4196])\n",
      "Token: 30 is\n",
      "torch.Size([4196])\n",
      "Token: 31 advocating\n",
      "torch.Size([4196])\n",
      "Token: 32 getting\n",
      "torch.Size([4196])\n",
      "Token: 33 the\n",
      "torch.Size([4196])\n",
      "Token: 34 US\n",
      "torch.Size([4196])\n",
      "Token: 35 back\n",
      "torch.Size([4196])\n",
      "Token: 36 to\n",
      "torch.Size([4196])\n",
      "Token: 37 work\n",
      "torch.Size([4196])\n",
      "Token: 38 by\n",
      "torch.Size([4196])\n",
      "Token: 39 Easter\n",
      "torch.Size([4196])\n",
      "Token: 40 and\n",
      "torch.Size([4196])\n",
      "Token: 41 using\n",
      "torch.Size([4196])\n",
      "Token: 42 the\n",
      "torch.Size([4196])\n",
      "Token: 43 coronavirus\n",
      "torch.Size([4196])\n",
      "Token: 44 to\n",
      "torch.Size([4196])\n",
      "Token: 45 stoke\n",
      "torch.Size([4196])\n",
      "Token: 46 xenophobia,\n",
      "torch.Size([4196])\n",
      "Token: 47 that\n",
      "torch.Size([4196])\n",
      "Token: 48 is\n",
      "torch.Size([4196])\n",
      "Token: 49 no\n",
      "torch.Size([4196])\n",
      "Token: 50 small\n",
      "torch.Size([4196])\n",
      "Token: 51 thing\n",
      "torch.Size([4196])\n",
      "Token: 52 for\n",
      "torch.Size([4196])\n",
      "Token: 53 which\n",
      "torch.Size([4196])\n",
      "Token: 54 we\n",
      "torch.Size([4196])\n",
      "Token: 55 should\n",
      "torch.Size([4196])\n",
      "Token: 56 be\n",
      "torch.Size([4196])\n",
      "Token: 57 very\n",
      "torch.Size([4196])\n",
      "Token: 58 grateful.\n",
      "torch.Size([4196])\n",
      "Token: 59 But\n",
      "torch.Size([4196])\n",
      "Token: 60 what\n",
      "torch.Size([4196])\n",
      "Token: 61 is\n",
      "torch.Size([4196])\n",
      "Token: 62 clear\n",
      "torch.Size([4196])\n",
      "Token: 63 is\n",
      "torch.Size([4196])\n",
      "Token: 64 that\n",
      "torch.Size([4196])\n",
      "Token: 65 Morrison\n",
      "torch.Size([4196])\n",
      "Token: 66 is\n",
      "torch.Size([4196])\n",
      "Token: 67 also\n",
      "torch.Size([4196])\n",
      "Token: 68 doing\n",
      "torch.Size([4196])\n",
      "Token: 69 his\n",
      "torch.Size([4196])\n",
      "Token: 70 level\n",
      "torch.Size([4196])\n",
      "Token: 71 best\n",
      "torch.Size([4196])\n",
      "Token: 72 to\n",
      "torch.Size([4196])\n",
      "Token: 73 keep\n",
      "torch.Size([4196])\n",
      "Token: 74 us\n",
      "torch.Size([4196])\n",
      "Token: 75 all\n",
      "torch.Size([4196])\n",
      "Token: 76 confused.\n",
      "torch.Size([4196])\n",
      "Token: 77 Tuesday\n",
      "torch.Size([4196])\n",
      "Token: 78 night’s\n",
      "torch.Size([4196])\n",
      "Token: 79 press\n",
      "torch.Size([4196])\n",
      "Token: 80 conference\n",
      "torch.Size([4196])\n",
      "Token: 81 was\n",
      "torch.Size([4196])\n",
      "Token: 82 the\n",
      "torch.Size([4196])\n",
      "Token: 83 prime\n",
      "torch.Size([4196])\n",
      "Token: 84 minister\n",
      "torch.Size([4196])\n",
      "Token: 85 at\n",
      "torch.Size([4196])\n",
      "Token: 86 his\n",
      "torch.Size([4196])\n",
      "Token: 87 bumbling,\n",
      "torch.Size([4196])\n",
      "Token: 88 inept\n",
      "torch.Size([4196])\n",
      "Token: 89 worst.\n",
      "torch.Size([4196])\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "flair_embedding_backward = FlairEmbeddings('news-backward')\n",
    "\n",
    "stacked_embedding = StackedEmbeddings([\n",
    "    glove_embedding,\n",
    "    flair_embedding_forward,\n",
    "    flair_embedding_backward    \n",
    "])\n",
    "\n",
    "sentence = Sentence(txt)\n",
    "stacked_embedding.embed(sentence)\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings\n",
    "\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "flair_embedding_backward = FlairEmbeddings('news-backward')\n",
    "\n",
    "document_embedding = DocumentPoolEmbeddings([\n",
    "    glove_embedding,\n",
    "    flair_embedding_forward,\n",
    "    flair_embedding_backward\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4196])\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence(txt)\n",
    "document_embedding.embed(sentence)\n",
    "print(sentence.get_embedding().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "document_lstm_embedding = DocumentRNNEmbeddings([\n",
    "    glove_embedding\n",
    "], rnn_type='LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 04:11:35,984 https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-dev.conllu not found in cache, downloading to /tmp/tmpfw84r95b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1668224B [00:00, 47269303.13B/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 04:11:36,068 copying /tmp/tmpfw84r95b to cache at /home/ec2-user/.flair/datasets/ud_english/en_ewt-ud-dev.conllu\n",
      "2020-03-26 04:11:36,071 removing temp file /tmp/tmpfw84r95b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 04:11:36,396 https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-test.conllu not found in cache, downloading to /tmp/tmpj9ep_11o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1662046B [00:00, 43052372.04B/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 04:11:36,490 copying /tmp/tmpj9ep_11o to cache at /home/ec2-user/.flair/datasets/ud_english/en_ewt-ud-test.conllu\n",
      "2020-03-26 04:11:36,494 removing temp file /tmp/tmpj9ep_11o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 04:11:37,308 https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-train.conllu not found in cache, downloading to /tmp/tmprhmhx02m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13303560B [00:00, 73724663.28B/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 04:11:37,532 copying /tmp/tmprhmhx02m to cache at /home/ec2-user/.flair/datasets/ud_english/en_ewt-ud-train.conllu\n",
      "2020-03-26 04:11:37,546 removing temp file /tmp/tmprhmhx02m\n",
      "2020-03-26 04:11:37,548 Reading data from /home/ec2-user/.flair/datasets/ud_english\n",
      "2020-03-26 04:11:37,549 Train: /home/ec2-user/.flair/datasets/ud_english/en_ewt-ud-train.conllu\n",
      "2020-03-26 04:11:37,550 Test: /home/ec2-user/.flair/datasets/ud_english/en_ewt-ud-test.conllu\n",
      "2020-03-26 04:11:37,550 Dev: /home/ec2-user/.flair/datasets/ud_english/en_ewt-ud-dev.conllu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import flair.datasets\n",
    "corpus = flair.datasets.UD_ENGLISH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12543\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus.train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:efficientnet]",
   "language": "python",
   "name": "conda-env-efficientnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
