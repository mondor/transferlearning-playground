{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2017-2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n",
      "#\r\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\"). You\r\n",
      "# may not use this file except in compliance with the License. A copy of\r\n",
      "# the License is located at\r\n",
      "#\r\n",
      "#     http://aws.amazon.com/apache2.0/\r\n",
      "#\r\n",
      "# or in the \"license\" file accompanying this file. This file is\r\n",
      "# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\r\n",
      "# ANY KIND, either express or implied. See the License for the specific\r\n",
      "# language governing permissions and limitations under the License.\r\n",
      "\r\n",
      "# For more information on creating a Dockerfile\r\n",
      "# https://docs.docker.com/compose/gettingstarted/#step-2-create-a-dockerfile\r\n",
      "# https://github.com/awslabs/amazon-sagemaker-examples/master/advanced_functionality/pytorch_extending_our_containers/pytorch_extending_our_containers.ipynb\r\n",
      "ARG REGION=us-east-1\r\n",
      "\r\n",
      "# SageMaker PyTorch image\r\n",
      "FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/pytorch-training:1.4.0-gpu-py3\r\n",
      "\r\n",
      "RUN pip install flair\r\n",
      "RUN pip install smart_open[gcp]\r\n",
      "\r\n",
      "ENV PATH=\"/opt/ml/code:${PATH}\"\r\n",
      "\r\n",
      "# /opt/ml and all subdirectories are utilized by SageMaker, we use the /code subdirectory to store our user code.\r\n",
      "COPY /flair /opt/ml/code\r\n",
      "\r\n",
      "# this environment variable is used by the SageMaker PyTorch container to determine our user code directory.\r\n",
      "ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\r\n",
      "\r\n",
      "# this environment variable is used by the SageMaker PyTorch container to determine our program entry point\r\n",
      "# for training and serving.\r\n",
      "# For more information: https://github.com/aws/sagemaker-pytorch-container\r\n",
      "ENV SAGEMAKER_PROGRAM multilabels.py\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  1.929MB\n",
      "Step 1/8 : ARG REGION=us-east-1\n",
      "Step 2/8 : FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/pytorch-training:1.4.0-gpu-py3\n",
      " ---> 8433beacd261\n",
      "Step 3/8 : RUN pip install flair\n",
      " ---> Using cache\n",
      " ---> 0e481f0033fb\n",
      "Step 4/8 : RUN pip install smart_open[gcp]\n",
      " ---> Using cache\n",
      " ---> 24145c15cdeb\n",
      "Step 5/8 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> b872249ef1a2\n",
      "Step 6/8 : COPY /flair /opt/ml/code\n",
      " ---> c8e2cddc3f03\n",
      "Step 7/8 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in e11d183a3848\n",
      "Removing intermediate container e11d183a3848\n",
      " ---> 8956cb63782e\n",
      "Step 8/8 : ENV SAGEMAKER_PROGRAM multilabels.py\n",
      " ---> Running in db1188359231\n",
      "Removing intermediate container db1188359231\n",
      " ---> 86f1223cd5d0\n",
      "Successfully built 86f1223cd5d0\n",
      "Successfully tagged flair_multilabels:latest\n",
      "The push refers to repository [953585160895.dkr.ecr.us-east-1.amazonaws.com/flair_multilabels]\n",
      "\n",
      "\u001b[1Bef9c9194: Preparing \n",
      "\u001b[1Bd972e10d: Preparing \n",
      "\u001b[1B45dc7b00: Preparing \n",
      "\u001b[1B400f035c: Preparing \n",
      "\u001b[1B94948a0d: Preparing \n",
      "\u001b[1Ba2814a55: Preparing \n",
      "\u001b[1B23b5a57b: Preparing \n",
      "\u001b[1B738dc081: Preparing \n",
      "\u001b[1B055a69f0: Preparing \n",
      "\u001b[1B9876f35f: Preparing \n",
      "\u001b[1Badb6f454: Preparing \n",
      "\u001b[1Bebde6a27: Preparing \n",
      "\u001b[1Bc62603ae: Preparing \n",
      "\u001b[1B82549d59: Preparing \n",
      "\u001b[1B22d4f50b: Preparing \n",
      "\u001b[1B8d6db1d7: Preparing \n",
      "\u001b[1Bc1a50da0: Preparing \n",
      "\u001b[1B37055bb7: Preparing \n",
      "\u001b[1B1f4a2873: Preparing \n",
      "\u001b[1B73532569: Preparing \n",
      "\u001b[1B20da503d: Preparing \n",
      "\u001b[1Bdadd4466: Preparing \n",
      "\u001b[1B74e50f52: Preparing \n",
      "\u001b[1B9e8d85dd: Preparing \n",
      "\u001b[1B74ebe255: Preparing \n",
      "\u001b[1B9683cb41: Preparing \n",
      "\u001b[1B42719515: Preparing \n",
      "\u001b[1B103e78c9: Preparing \n",
      "\u001b[1Be637fbff: Preparing \n",
      "\u001b[1Bb9b0fb21: Layer already exists 6kB27A\u001b[1K\u001b[K\u001b[30A\u001b[1K\u001b[K\u001b[25A\u001b[1K\u001b[K\u001b[22A\u001b[1K\u001b[K\u001b[21A\u001b[1K\u001b[K\u001b[19A\u001b[1K\u001b[K\u001b[18A\u001b[1K\u001b[K\u001b[17A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[30A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[Klatest: digest: sha256:d5b39ec4f3df512d6488c11ec8f6b5f84c0ac00cde3f4f9d68b06e377586065a size: 6622\n"
     ]
    }
   ],
   "source": [
    "!./build_and_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting test data\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file('sagemaker-us-east-1-953585160895',\n",
    "                 'data/5ea9ec56ea2e7/preprocess_data.txt', \n",
    "                 'local_test/preprocess_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name SageMakerDev to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the short-lived AWS credentials found in session. They might expire while running.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmprjqazos5_algo-1-eqwxk_1 ... \n",
      "\u001b[1BAttaching to tmprjqazos5_algo-1-eqwxk_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:55,484 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:55,486 sagemaker-containers INFO     Failed to parse hyperparameter column_names value _id,message,image_concept,image,published,disabled to Json.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:55,486 sagemaker-containers INFO     Failed to parse hyperparameter target_names value published,disabled to Json.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:55,511 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:55,514 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:55,516 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:55,516 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:55,517 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:55,517 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m /opt/conda/bin/python -m pip install . \n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Processing /tmp/tmp0ui06kdk/module_dir\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Building wheels for collected packages: default-user-module-name\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m   Building wheel for default-user-module-name (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m \u001b[?25h  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=9337 sha256=e898713a999f9adc2b857623f36f652c7371fc1946d774cbef05a5ca3642b6ce\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-vngjo1zd/wheels/99/c3/18/bcdf04b5a3ae906870e65322fe8406c002ebd27adb93914b6b\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Successfully built default-user-module-name\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Installing collected packages: default-user-module-name\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Successfully installed default-user-module-name-1.0.0\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:57,842 sagemaker-containers INFO     Failed to parse hyperparameter column_names value _id,message,image_concept,image,published,disabled to Json.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:57,842 sagemaker-containers INFO     Failed to parse hyperparameter target_names value published,disabled to Json.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:57,857 sagemaker-containers INFO     Failed to parse hyperparameter column_names value _id,message,image_concept,image,published,disabled to Json.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:57,857 sagemaker-containers INFO     Failed to parse hyperparameter target_names value published,disabled to Json.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:57,883 sagemaker-containers INFO     Failed to parse hyperparameter column_names value _id,message,image_concept,image,published,disabled to Json.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:57,883 sagemaker-containers INFO     Failed to parse hyperparameter target_names value published,disabled to Json.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:15:57,909 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"current_host\": \"algo-1-eqwxk\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m         \"algo-1-eqwxk\"\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m         \"column_names\": \"_id,message,image_concept,image,published,disabled\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m         \"target_names\": \"published,disabled\"\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"job_name\": \"flair_multilabels-2020-04-30-05-15-51-576\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"master_hostname\": \"algo-1-eqwxk\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"module_name\": \"multilabels\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"num_gpus\": 1,\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m         \"current_host\": \"algo-1-eqwxk\",\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m             \"algo-1-eqwxk\"\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     \"user_entry_point\": \"multilabels.py\"\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_HOSTS=[\"algo-1-eqwxk\"]\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_HPS={\"column_names\":\"_id,message,image_concept,image,published,disabled\",\"epochs\":1,\"target_names\":\"published,disabled\"}\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_USER_ENTRY_POINT=multilabels.py\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-eqwxk\",\"hosts\":[\"algo-1-eqwxk\"]}\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_CURRENT_HOST=algo-1-eqwxk\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_MODULE_NAME=multilabels\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_NUM_GPUS=1\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-eqwxk\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-eqwxk\"],\"hyperparameters\":{\"column_names\":\"_id,message,image_concept,image,published,disabled\",\"epochs\":1,\"target_names\":\"published,disabled\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"flair_multilabels-2020-04-30-05-15-51-576\",\"log_level\":20,\"master_hostname\":\"algo-1-eqwxk\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"multilabels\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-eqwxk\",\"hosts\":[\"algo-1-eqwxk\"]},\"user_entry_point\":\"multilabels.py\"}\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_USER_ARGS=[\"--column_names\",\"_id,message,image_concept,image,published,disabled\",\"--epochs\",\"1\",\"--target_names\",\"published,disabled\"]\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_HP_COLUMN_NAMES=_id,message,image_concept,image,published,disabled\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m SM_HP_TARGET_NAMES=published,disabled\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m /opt/conda/bin/python multilabels.py --column_names _id,message,image_concept,image,published,disabled --epochs 1 --target_names published,disabled\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m class: (published), train: 342, val: 156\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m class: (disabled), train: 1050, val: 441\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:16:01,243 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/twitter.gensim.vectors.npy not found in cache, downloading to /tmp/tmpvglma3bv\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:16:53,026 copying /tmp/tmpvglma3bv to cache at /root/.flair/embeddings/twitter.gensim.vectors.npy\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:16:53,492 removing temp file /tmp/tmpvglma3bv\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:16:54,235 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/twitter.gensim not found in cache, downloading to /tmp/tmpn4xkpy8w\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:17:03,296 copying /tmp/tmpn4xkpy8w to cache at /root/.flair/embeddings/twitter.gensim\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:17:03,365 removing temp file /tmp/tmpn4xkpy8w\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m TextClassifier(\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m   (document_embeddings): DocumentRNNEmbeddings(\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     (embeddings): StackedEmbeddings(\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m       (list_embedding_0): WordEmbeddings('twitter')\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     )\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     (word_reprojection_map): Linear(in_features=100, out_features=128, bias=True)\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     (rnn): GRU(128, 128, batch_first=True)\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m     (dropout): Dropout(p=0.5, inplace=False)\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m   )\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m   (decoder): Linear(in_features=128, out_features=2, bias=True)\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m   (loss_function): BCEWithLogitsLoss()\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m   (beta): 1.0\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m   (weights): None\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m   (weight_tensor) None\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m )\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 0, train loss 0.04465789720416069\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 10, train loss 0.044170670211315155\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 20, train loss 0.03276388347148895\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 30, train loss 0.04773316904902458\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 40, train loss 0.048604726791381836\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 50, train loss 0.049598563462495804\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 60, train loss 0.05342046171426773\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 70, train loss 0.036984384059906006\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 80, train loss 0.029276322573423386\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 90, train loss 0.045682527124881744\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 100, train loss 0.05259506404399872\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 110, train loss 0.041718319058418274\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Epoch 0, Batch 120, train loss 0.033205632120370865\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m > Epoch 0, train loss 0.06265871558638139\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m > Epoch 0, val loss 0.043353669357858914, accuracy 0.6164154103852596, f1 0.6164154103852596\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m Saved model.\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m success!\n",
      "\u001b[36malgo-1-eqwxk_1  |\u001b[0m 2020-04-30 05:17:33,243 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmprjqazos5_algo-1-eqwxk_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "if subprocess.call('nvidia-smi') == 0:\n",
    "    ## Set type to GPU if one is present\n",
    "    instance_type = 'local_gpu'\n",
    "    \n",
    "print(\"Instance type = \" + instance_type)\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {\n",
    "    'epochs': 1,\n",
    "    'column_names': '_id,message,image_concept,image,published,disabled',\n",
    "    'target_names': 'published,disabled'    \n",
    "}\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name='flair_multilabels:latest',\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit('file://local_test')\n",
    "\n",
    "\n",
    "\n",
    "# connect docker\n",
    "# > docker run --rm -ti -v $(pwd)/local_test:/opt/ml/input/data/training flair_multilabels bash\n",
    "\n",
    "# inside docker\n",
    "# > cd /opt/ml/code\n",
    "# > export SM_CHANNEL_TRAINING=/opt/ml/input/data/training/\n",
    "# > export SM_MODEL_DIR=/opt/ml/\n",
    "# > python multilabels.py --column_names _id,message,image_concept,image,published,disabled --epochs 1 --target_names published,disabled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-953585160895/data/flair_test\n"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "\n",
    "sess = sage.Session()\n",
    "\n",
    "data_location = sess.upload_data('local_test', key_prefix='data/flair_test')\n",
    "print(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953585160895.dkr.ecr.us-east-1.amazonaws.com/flair_multilabels:latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "algorithm_name = 'flair_multilabels'\n",
    "\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name SageMakerDev to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 06:28:18 Starting - Starting the training job...\n",
      "2020-04-29 06:28:21 Starting - Launching requested ML instances......\n",
      "2020-04-29 06:29:25 Starting - Preparing the instances for training......\n",
      "2020-04-29 06:30:34 Downloading - Downloading input data...\n",
      "2020-04-29 06:30:57 Training - Downloading the training image...................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:39,962 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:39,963 sagemaker-containers INFO     Failed to parse hyperparameter column-names value _id,message,image_concept,published,disabled to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:39,964 sagemaker-containers INFO     Failed to parse hyperparameter target-names value published,disabled to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:39,966 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:39,979 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:43,005 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:43,010 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:43,010 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:43,010 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:43,011 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpk7yz0r0h/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=9334 sha256=30a8438341b1879af05b717ea1e0a508e6b478cafa8e3cacb431fd92cd9971bf\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2i3iq22w/wheels/cd/ba/2b/50b83040eb153ff0d322b3ec25944f538dc4584a1281f0f57f\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:45,743 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:45,744 sagemaker-containers INFO     Failed to parse hyperparameter column-names value _id,message,image_concept,published,disabled to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:45,744 sagemaker-containers INFO     Failed to parse hyperparameter target-names value published,disabled to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:45,758 sagemaker-containers INFO     Failed to parse hyperparameter column-names value _id,message,image_concept,published,disabled to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:45,758 sagemaker-containers INFO     Failed to parse hyperparameter target-names value published,disabled to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:45,760 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:45,773 sagemaker-containers INFO     Failed to parse hyperparameter column-names value _id,message,image_concept,published,disabled to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:45,774 sagemaker-containers INFO     Failed to parse hyperparameter target-names value published,disabled to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:45,776 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:45,789 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"column-names\": \"_id,message,image_concept,published,disabled\",\n",
      "        \"epochs\": 1,\n",
      "        \"target-names\": \"published,disabled\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"flair-test-2020-04-29-06-28-16-832\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"multilabels\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"multilabels.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"column-names\":\"_id,message,image_concept,published,disabled\",\"epochs\":1,\"target-names\":\"published,disabled\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=multilabels.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=multilabels\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"column-names\":\"_id,message,image_concept,published,disabled\",\"epochs\":1,\"target-names\":\"published,disabled\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"flair-test-2020-04-29-06-28-16-832\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"multilabels\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"multilabels.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--column-names\",\"_id,message,image_concept,published,disabled\",\"--epochs\",\"1\",\"--target-names\",\"published,disabled\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_COLUMN-NAMES=_id,message,image_concept,published,disabled\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET-NAMES=published,disabled\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python multilabels.py --column-names _id,message,image_concept,published,disabled --epochs 1 --target-names published,disabled\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mclass: (published), train: 510, val: 225\u001b[0m\n",
      "\u001b[34mclass: (disabled), train: 9619, val: 4117\u001b[0m\n",
      "\u001b[34m2020-04-29 06:34:51,695 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/twitter.gensim.vectors.npy not found in cache, downloading to /tmp/tmpw860a7ej\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-04-29 06:34:38 Training - Training image download completed. Training in progress.\u001b[34m2020-04-29 06:35:10,255 copying /tmp/tmpw860a7ej to cache at /root/.flair/embeddings/twitter.gensim.vectors.npy\u001b[0m\n",
      "\u001b[34m2020-04-29 06:35:10,722 removing temp file /tmp/tmpw860a7ej\u001b[0m\n",
      "\u001b[34m2020-04-29 06:35:11,580 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/twitter.gensim not found in cache, downloading to /tmp/tmpxl4cr_xi\u001b[0m\n",
      "\u001b[34m2020-04-29 06:35:14,943 copying /tmp/tmpxl4cr_xi to cache at /root/.flair/embeddings/twitter.gensim\u001b[0m\n",
      "\u001b[34m2020-04-29 06:35:15,019 removing temp file /tmp/tmpxl4cr_xi\u001b[0m\n",
      "\u001b[34mTextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('twitter')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=128, bias=True)\n",
      "    (rnn): GRU(128, 128, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (loss_function): BCEWithLogitsLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 0, train loss 0.04380995035171509\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 10, train loss 0.05077163130044937\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 20, train loss 0.04098829999566078\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 30, train loss 0.0464705266058445\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 40, train loss 0.038212139159440994\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 50, train loss 0.04781784862279892\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 60, train loss 0.041682761162519455\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 70, train loss 0.043147843331098557\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 80, train loss 0.05074085295200348\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 90, train loss 0.04309047758579254\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 100, train loss 0.05401081591844559\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 110, train loss 0.03652673959732056\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 120, train loss 0.04409625008702278\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 130, train loss 0.03972477838397026\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 140, train loss 0.04553363844752312\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 150, train loss 0.04157314822077751\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 160, train loss 0.04365931451320648\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 170, train loss 0.04083770886063576\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 180, train loss 0.03617589920759201\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 190, train loss 0.04079752042889595\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 200, train loss 0.03742479532957077\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 210, train loss 0.03867212310433388\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 220, train loss 0.03654542565345764\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 230, train loss 0.03799483925104141\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 240, train loss 0.03612540662288666\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 250, train loss 0.04744282737374306\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 260, train loss 0.03910881653428078\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 270, train loss 0.03871079906821251\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 280, train loss 0.04553329199552536\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 290, train loss 0.049919288605451584\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 300, train loss 0.04289061576128006\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 310, train loss 0.04058978334069252\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 320, train loss 0.03698071837425232\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 330, train loss 0.03767642751336098\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 340, train loss 0.04309941083192825\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 350, train loss 0.03909110650420189\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 360, train loss 0.042226362973451614\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 370, train loss 0.039075225591659546\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 380, train loss 0.0409226156771183\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 390, train loss 0.0323229543864727\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 400, train loss 0.033697642385959625\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 410, train loss 0.03802986815571785\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 420, train loss 0.04021839052438736\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 430, train loss 0.04459666460752487\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 440, train loss 0.04640435799956322\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 450, train loss 0.05004560202360153\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 460, train loss 0.037548039108514786\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 470, train loss 0.04008924961090088\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 480, train loss 0.0328320674598217\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 490, train loss 0.04365149512887001\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 500, train loss 0.03836128115653992\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 510, train loss 0.05040333420038223\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 520, train loss 0.039163921028375626\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 530, train loss 0.03544836491346359\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 540, train loss 0.04838358983397484\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 550, train loss 0.04112857207655907\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 560, train loss 0.04279462248086929\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 570, train loss 0.043297179043293\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 580, train loss 0.03665468841791153\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 590, train loss 0.03499773517251015\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 600, train loss 0.030940819531679153\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 610, train loss 0.035718757659196854\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 620, train loss 0.041800301522016525\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 630, train loss 0.045824624598026276\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 640, train loss 0.03966822475194931\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 650, train loss 0.03519076853990555\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 660, train loss 0.04670853912830353\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 670, train loss 0.03525586053729057\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 680, train loss 0.040642380714416504\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 690, train loss 0.03824204206466675\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 700, train loss 0.037609558552503586\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 710, train loss 0.04173637926578522\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 720, train loss 0.03613387048244476\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 730, train loss 0.03755200654268265\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 740, train loss 0.040597956627607346\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 750, train loss 0.03332716226577759\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 760, train loss 0.028892215341329575\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 770, train loss 0.03755436837673187\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 780, train loss 0.035245656967163086\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 790, train loss 0.040199100971221924\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 800, train loss 0.03849095106124878\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 810, train loss 0.03653649240732193\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 820, train loss 0.03866252303123474\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 830, train loss 0.041854165494441986\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 840, train loss 0.0366855151951313\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 850, train loss 0.04734758287668228\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 860, train loss 0.040946729481220245\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 870, train loss 0.03965593874454498\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 880, train loss 0.029664820060133934\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 890, train loss 0.03528548404574394\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 900, train loss 0.041958313435316086\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 910, train loss 0.04466338828206062\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 920, train loss 0.03533408045768738\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 930, train loss 0.036321137100458145\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 940, train loss 0.04640059173107147\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 950, train loss 0.04278178885579109\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 960, train loss 0.03399223834276199\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 970, train loss 0.026192370802164078\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 980, train loss 0.03227938711643219\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 990, train loss 0.04027365520596504\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1000, train loss 0.03961722552776337\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1010, train loss 0.030055051669478416\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1020, train loss 0.04206185042858124\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1030, train loss 0.03920343890786171\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1040, train loss 0.038688600063323975\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1050, train loss 0.04125767946243286\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1060, train loss 0.03220805525779724\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1070, train loss 0.04222063347697258\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1080, train loss 0.03369564190506935\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1090, train loss 0.04521113634109497\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1100, train loss 0.02694462612271309\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1110, train loss 0.043474532663822174\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1120, train loss 0.046658165752887726\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1130, train loss 0.04433155804872513\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1140, train loss 0.023126550018787384\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1150, train loss 0.04133475944399834\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1160, train loss 0.028502700850367546\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1170, train loss 0.040491070598363876\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1180, train loss 0.03422931209206581\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1190, train loss 0.036899399012327194\u001b[0m\n",
      "\u001b[34mEpoch 0, Batch 1200, train loss 0.03386617824435234\u001b[0m\n",
      "\u001b[34m> Epoch 0, train loss 0.07757364973015418\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m> Epoch 0, val loss 0.03785077191096525, accuracy 0.5968447719944726, f1 0.5968396343790907\u001b[0m\n",
      "\u001b[34mSaved model.\u001b[0m\n",
      "\u001b[34msuccess!\u001b[0m\n",
      "\u001b[34m2020-04-29 06:38:53,960 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-04-29 06:39:48 Uploading - Uploading generated training model\n",
      "2020-04-29 06:39:48 Completed - Training job completed\n",
      "Training seconds: 554\n",
      "Billable seconds: 554\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "instance_type = 'ml.m4.xlarge'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      base_job_name='flair-test',\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name=ecr_image,\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit(data_location)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:efficientnet]",
   "language": "python",
   "name": "conda-env-efficientnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
