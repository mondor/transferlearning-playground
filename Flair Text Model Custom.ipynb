{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "published 720, disabled 720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>message</th>\n",
       "      <th>image_concept</th>\n",
       "      <th>published</th>\n",
       "      <th>disabled</th>\n",
       "      <th>available</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e5836fee917e8d9a8a7b277</td>\n",
       "      <td>endless blues greatbarrierreef australia whits...</td>\n",
       "      <td>seascape water shoal sea turquoise sun tropica...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>seascape water shoal sea turquoise sun tropica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e58343ded065ad79e312f3d</td>\n",
       "      <td>hamiltonisland</td>\n",
       "      <td>tree travel vacation seashore water hotel isla...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tree travel vacation seashore water hotel isla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e57dc939e88b6be2ac42800</td>\n",
       "      <td>we are going coconuts for hamiltonisland here ...</td>\n",
       "      <td>relaxation beach sea vacation sand recreation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>relaxation beach sea vacation sand recreation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e55dca437fa5927dcdf02f3</td>\n",
       "      <td>en route to gbr embrace the elevation in luxur...</td>\n",
       "      <td>nature travel diving water sea underwater ocea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>nature travel diving water sea underwater ocea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e55d69eb9e5b725cd7ba02f</td>\n",
       "      <td>golf course views hamiltonislandgolfcourse whi...</td>\n",
       "      <td>outdoors landscape beach sky nature rural nope...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>outdoors landscape beach sky nature rural nope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>5e4e3124497f22be9069f067</td>\n",
       "      <td>golf trips with the boys are always wicked and...</td>\n",
       "      <td>sky water seashore sea travel winter ship land...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sky water seashore sea travel winter ship land...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>5e4e3124ffb21abead202386</td>\n",
       "      <td>golf trips with the boys are always wicked and...</td>\n",
       "      <td>travel golf ocean grass water sand nature sea ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>travel golf ocean grass water sand nature sea ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>5e4e3124ffb21abead202385</td>\n",
       "      <td>throwback to that time i was warm and tanned q...</td>\n",
       "      <td>watercraft water people noperson recreation se...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>watercraft water people noperson recreation se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>5e4e3123164d73be9b8cd43e</td>\n",
       "      <td>golf trips with the boys are always wicked and...</td>\n",
       "      <td>adult people class girl grouptogether portrait...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>adult people class girl grouptogether portrait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>5e4e3123164d73be9b8cd43f</td>\n",
       "      <td>golf trips with the boys are always wicked and...</td>\n",
       "      <td>travel golf sea nature landscape rural noperso...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>travel golf sea nature landscape rural noperso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id  \\\n",
       "0     5e5836fee917e8d9a8a7b277   \n",
       "1     5e58343ded065ad79e312f3d   \n",
       "2     5e57dc939e88b6be2ac42800   \n",
       "3     5e55dca437fa5927dcdf02f3   \n",
       "4     5e55d69eb9e5b725cd7ba02f   \n",
       "...                        ...   \n",
       "1435  5e4e3124497f22be9069f067   \n",
       "1436  5e4e3124ffb21abead202386   \n",
       "1437  5e4e3124ffb21abead202385   \n",
       "1438  5e4e3123164d73be9b8cd43e   \n",
       "1439  5e4e3123164d73be9b8cd43f   \n",
       "\n",
       "                                                message  \\\n",
       "0     endless blues greatbarrierreef australia whits...   \n",
       "1                                        hamiltonisland   \n",
       "2     we are going coconuts for hamiltonisland here ...   \n",
       "3     en route to gbr embrace the elevation in luxur...   \n",
       "4     golf course views hamiltonislandgolfcourse whi...   \n",
       "...                                                 ...   \n",
       "1435  golf trips with the boys are always wicked and...   \n",
       "1436  golf trips with the boys are always wicked and...   \n",
       "1437  throwback to that time i was warm and tanned q...   \n",
       "1438  golf trips with the boys are always wicked and...   \n",
       "1439  golf trips with the boys are always wicked and...   \n",
       "\n",
       "                                          image_concept  published  disabled  \\\n",
       "0     seascape water shoal sea turquoise sun tropica...          1         0   \n",
       "1     tree travel vacation seashore water hotel isla...          1         0   \n",
       "2     relaxation beach sea vacation sand recreation ...          1         0   \n",
       "3     nature travel diving water sea underwater ocea...          1         0   \n",
       "4     outdoors landscape beach sky nature rural nope...          1         0   \n",
       "...                                                 ...        ...       ...   \n",
       "1435  sky water seashore sea travel winter ship land...          0         1   \n",
       "1436  travel golf ocean grass water sand nature sea ...          0         1   \n",
       "1437  watercraft water people noperson recreation se...          0         1   \n",
       "1438  adult people class girl grouptogether portrait...          0         1   \n",
       "1439  travel golf sea nature landscape rural noperso...          0         1   \n",
       "\n",
       "      available                                               text  \n",
       "0             1  seascape water shoal sea turquoise sun tropica...  \n",
       "1             1  tree travel vacation seashore water hotel isla...  \n",
       "2             1  relaxation beach sea vacation sand recreation ...  \n",
       "3             1  nature travel diving water sea underwater ocea...  \n",
       "4             1  outdoors landscape beach sky nature rural nope...  \n",
       "...         ...                                                ...  \n",
       "1435          1  sky water seashore sea travel winter ship land...  \n",
       "1436          1  travel golf ocean grass water sand nature sea ...  \n",
       "1437          1  watercraft water people noperson recreation se...  \n",
       "1438          1  adult people class girl grouptogether portrait...  \n",
       "1439          1  travel golf sea nature landscape rural noperso...  \n",
       "\n",
       "[1440 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('flair-vgg16-data.csv', names=['_id', 'message', 'image_concept', 'published', 'disabled'])\n",
    "df['available'] = 0\n",
    "\n",
    "all_images_path = 'data/all_images'\n",
    "for i, row in df.iterrows():\n",
    "    if os.path.isfile(os.path.join(all_images_path, row['_id'] + '.jpg')):\n",
    "        df.at[i, 'available']= 1    \n",
    "        \n",
    "df_published = df.loc[df.query('available == 1 and published == 1').index]\n",
    "df_published['text'] = df_published['image_concept'] + ' ' + df_published['message']\n",
    "df_published = df_published.loc[df_published['text'].notnull()]\n",
    "\n",
    "published_count = len(df_published)\n",
    "\n",
    "df_disabled = df.loc[df.query('available == 1 and disabled == 1').index]\n",
    "df_disabled['text'] = df_disabled['image_concept'] + ' ' + df_disabled['message']\n",
    "df_disabled = df_disabled.loc[df_disabled['text'].notnull()]\n",
    "\n",
    "\n",
    "df_disabled = df_disabled[:published_count]\n",
    "\n",
    "print(f\"published {len(df_published)}, disabled {len(df_disabled)}\")\n",
    "\n",
    "df_all = pd.concat([df_published, df_disabled], ignore_index=True)\n",
    "\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 864, val 345, test 231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, validation_df = train_test_split(df_all, test_size=0.4, random_state=42)\n",
    "validation_df, test_df = train_test_split(validation_df, test_size=0.4, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"train {len(train_df)}, val {len(validation_df)}, test {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import (\n",
    "    Sentence, \n",
    "    WordEmbeddings, \n",
    "    FlairEmbeddings, \n",
    "    StackedEmbeddings, \n",
    "    DocumentRNNEmbeddings,\n",
    "    BytePairEmbeddings\n",
    ")\n",
    "from flair.training_utils import store_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('twitter')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (rnn): GRU(100, 128, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "def get_batches(df, batch_size=16):\n",
    "    n_batches = len(df)//batch_size    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        x = [Sentence(txt) for txt in df[i:i+batch_size]['text']]\n",
    "        y = [1 if label else 0 for label in df[i:i+batch_size]['published']]\n",
    "        yield x, torch.FloatTensor(y)\n",
    "    \n",
    "    \n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.df = df\n",
    "        self.document_embeddings = DocumentRNNEmbeddings([\n",
    "            WordEmbeddings('twitter'),\n",
    "#            BytePairEmbeddings('en')\n",
    "#             FlairEmbeddings('news-forward'),\n",
    "#             FlairEmbeddings('news-backward')\n",
    "        ], hidden_size=128)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, sentences):\n",
    "        self.document_embeddings.embed(sentences)\n",
    "        \n",
    "        text_embedding_list = [\n",
    "            s.embedding.unsqueeze(0) for s in sentences\n",
    "        ]\n",
    "        \n",
    "        text_embedding_tensor = torch.cat(text_embedding_list, 0).cuda()\n",
    "        \n",
    "        out = self.sig(self.fc(text_embedding_tensor))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "model = MyModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, train loss 0.041444361209869385\n",
      "Epoch 0, Batch 10, train loss 0.052553366869688034\n",
      "Epoch 0, Batch 20, train loss 0.04126397520303726\n",
      "Epoch 0, Batch 30, train loss 0.04194075986742973\n",
      "Epoch 0, Batch 40, train loss 0.05388794094324112\n",
      "Epoch 0, Batch 50, train loss 0.04926455020904541\n",
      "> Epoch 0, train loss 0.04331002122274152\n",
      "> Epoch 0, val loss 0.04157462310099947\n",
      "Saved model.\n",
      "Epoch 1, Batch 0, train loss 0.04449247568845749\n",
      "Epoch 1, Batch 10, train loss 0.04590047150850296\n",
      "Epoch 1, Batch 20, train loss 0.04555549472570419\n",
      "Epoch 1, Batch 30, train loss 0.045813318341970444\n",
      "Epoch 1, Batch 40, train loss 0.043537646532058716\n",
      "Epoch 1, Batch 50, train loss 0.040530726313591\n",
      "> Epoch 1, train loss 0.04139460802630142\n",
      "> Epoch 1, val loss 0.040946247612220654\n",
      "Saved model.\n",
      "Epoch 2, Batch 0, train loss 0.042425207793712616\n",
      "Epoch 2, Batch 10, train loss 0.0397714227437973\n",
      "Epoch 2, Batch 20, train loss 0.03969942778348923\n",
      "Epoch 2, Batch 30, train loss 0.050785575062036514\n",
      "Epoch 2, Batch 40, train loss 0.03759326785802841\n",
      "Epoch 2, Batch 50, train loss 0.03753765672445297\n",
      "> Epoch 2, train loss 0.03988508973270655\n",
      "> Epoch 2, val loss 0.036236551101656925\n",
      "Saved model.\n",
      "Epoch 3, Batch 0, train loss 0.03691690415143967\n",
      "Epoch 3, Batch 10, train loss 0.03815896064043045\n",
      "Epoch 3, Batch 20, train loss 0.03342404216527939\n",
      "Epoch 3, Batch 30, train loss 0.029255375266075134\n",
      "Epoch 3, Batch 40, train loss 0.030024610459804535\n",
      "Epoch 3, Batch 50, train loss 0.020506732165813446\n",
      "> Epoch 3, train loss 0.030513909438418016\n",
      "> Epoch 3, val loss 0.022082885883856512\n",
      "Saved model.\n",
      "Epoch 4, Batch 0, train loss 0.03519265353679657\n",
      "Epoch 4, Batch 10, train loss 0.01749364659190178\n",
      "Epoch 4, Batch 20, train loss 0.03517903387546539\n",
      "Epoch 4, Batch 30, train loss 0.023485584184527397\n",
      "Epoch 4, Batch 40, train loss 0.013394259847700596\n",
      "Epoch 4, Batch 50, train loss 0.039026446640491486\n",
      "> Epoch 4, train loss 0.021732301416772383\n",
      "> Epoch 4, val loss 0.013750273674942444\n",
      "Saved model.\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, epochs, lr, train_df, val_df, checkpoint_file, early_stopping=5):        \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_loss = np.inf\n",
    "    no_improvement = 0\n",
    "\n",
    "    if train_on_gpu:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    for epoch in range(epochs):        \n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        # Train\n",
    "        model.train()        \n",
    "        for i, (sentences, labels) in enumerate(get_batches(train_df)):         \n",
    "            if train_on_gpu:\n",
    "                labels = labels.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = model(sentences)\n",
    "            loss = criterion(out.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "            store_embeddings(sentences, 'cpu')\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f\"Epoch {epoch}, Batch {i}, train loss {loss.item()/labels.size(0)}\")\n",
    "            \n",
    "            \n",
    "        train_loss = total_train_loss/len(train_df)\n",
    "        print(f\"> Epoch {epoch}, train loss {train_loss}\")\n",
    "        \n",
    "        # Eval\n",
    "        model.eval()\n",
    "        for sentences, labels in get_batches(val_df):\n",
    "            if train_on_gpu:\n",
    "                labels = labels.cuda()\n",
    "            \n",
    "            out = model(sentences)\n",
    "            loss = criterion(out.squeeze(), labels)\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            store_embeddings(sentences, 'cpu')\n",
    "            \n",
    "            \n",
    "        val_loss = total_val_loss / len(val_df)\n",
    "        \n",
    "        print(f\"> Epoch {epoch}, val loss {val_loss}\")\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            no_improvement = 0\n",
    "            torch.save(model.state_dict(), checkpoint_file)\n",
    "            print(\"Saved model.\")\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            print(\"No improvement.\")\n",
    "            if no_improvement >= early_stopping:\n",
    "                print(f\"Early Stopping\")\n",
    "                break\n",
    "            \n",
    "                                              \n",
    "checkpoint_file = 'flair_text_model_custom.pt'      \n",
    "lr = 0.005\n",
    "epochs = 5            \n",
    "\n",
    "train_model(model, epochs, lr, train_df, validation_df, checkpoint_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/231 correct. Accuracy: 90.04329004329004 %\n"
     ]
    }
   ],
   "source": [
    "def eval_model(model, test_df):\n",
    "    if train_on_gpu:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    for i, (sentences, labels) in enumerate(get_batches(test_df)):\n",
    "        if train_on_gpu:\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        out = model(sentences)\n",
    "        pred = torch.round(out.squeeze())\n",
    "        correct = (pred == labels)\n",
    "        correct = correct.cpu().numpy() if train_on_gpu else correct.numpy()\n",
    "        \n",
    "        num_correct += np.sum(correct)\n",
    "        \n",
    "        store_embeddings(sentences, 'cpu')\n",
    "        \n",
    "    total = len(test_df)\n",
    "    print(f\"{num_correct}/{total} correct. Accuracy: {num_correct*100/total} %\")\n",
    "    \n",
    "    \n",
    "best_model = MyModel()\n",
    "best_model.load_state_dict(torch.load(checkpoint_file))\n",
    "eval_model(best_model, test_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:efficientnet]",
   "language": "python",
   "name": "conda-env-efficientnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
