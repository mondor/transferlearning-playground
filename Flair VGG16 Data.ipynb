{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('flair-vgg16-data.csv', names=['_id', 'message', 'image_concept', 'published', 'disabled'])\n",
    "df['available'] = 0\n",
    "\n",
    "all_images_path = 'data/all_images'\n",
    "for i, row in df.iterrows():\n",
    "    if os.path.isfile(os.path.join(all_images_path, row['_id'] + '.jpg')):\n",
    "        df.at[i, 'available']= 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>message</th>\n",
       "      <th>image_concept</th>\n",
       "      <th>published</th>\n",
       "      <th>disabled</th>\n",
       "      <th>available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e5836fee917e8d9a8a7b277</td>\n",
       "      <td>endless blues greatbarrierreef australia whits...</td>\n",
       "      <td>seascape water shoal sea turquoise sun tropica...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e58343ded065ad79e312f3d</td>\n",
       "      <td>hamiltonisland</td>\n",
       "      <td>tree travel vacation seashore water hotel isla...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e57dc939e88b6be2ac42800</td>\n",
       "      <td>we are going coconuts for hamiltonisland here ...</td>\n",
       "      <td>relaxation beach sea vacation sand recreation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e55dca437fa5927dcdf02f3</td>\n",
       "      <td>en route to gbr embrace the elevation in luxur...</td>\n",
       "      <td>nature travel diving water sea underwater ocea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e55d69eb9e5b725cd7ba02f</td>\n",
       "      <td>golf course views hamiltonislandgolfcourse whi...</td>\n",
       "      <td>outdoors landscape beach sky nature rural nope...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8052</th>\n",
       "      <td>5e253779f1b8d48ba5de7d32</td>\n",
       "      <td>colours so bright they hurt your eyes tropical...</td>\n",
       "      <td>outdoors nature scenery landscape water land o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>5e252d334610948976f731e5</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>human person patient therapy massage heel spa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>5e252d334610948976f731e6</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>plant paper text flower blossom</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8055</th>\n",
       "      <td>5e252d3342307c89757703c0</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>person human finger hand dating face arm</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8056</th>\n",
       "      <td>5e252d33f7b8d8898b9e841f</td>\n",
       "      <td>호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...</td>\n",
       "      <td>human person patient massage therapy spa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8057 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id  \\\n",
       "0     5e5836fee917e8d9a8a7b277   \n",
       "1     5e58343ded065ad79e312f3d   \n",
       "2     5e57dc939e88b6be2ac42800   \n",
       "3     5e55dca437fa5927dcdf02f3   \n",
       "4     5e55d69eb9e5b725cd7ba02f   \n",
       "...                        ...   \n",
       "8052  5e253779f1b8d48ba5de7d32   \n",
       "8053  5e252d334610948976f731e5   \n",
       "8054  5e252d334610948976f731e6   \n",
       "8055  5e252d3342307c89757703c0   \n",
       "8056  5e252d33f7b8d8898b9e841f   \n",
       "\n",
       "                                                message  \\\n",
       "0     endless blues greatbarrierreef australia whits...   \n",
       "1                                        hamiltonisland   \n",
       "2     we are going coconuts for hamiltonisland here ...   \n",
       "3     en route to gbr embrace the elevation in luxur...   \n",
       "4     golf course views hamiltonislandgolfcourse whi...   \n",
       "...                                                 ...   \n",
       "8052  colours so bright they hurt your eyes tropical...   \n",
       "8053  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "8054  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "8055  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "8056  호 주 학 생 비 자 치 료 마 사 지 과 정 치 료 마 사 지 과 정 은 마 사 ...   \n",
       "\n",
       "                                          image_concept  published  disabled  \\\n",
       "0     seascape water shoal sea turquoise sun tropica...          1         0   \n",
       "1     tree travel vacation seashore water hotel isla...          1         0   \n",
       "2     relaxation beach sea vacation sand recreation ...          1         0   \n",
       "3     nature travel diving water sea underwater ocea...          1         0   \n",
       "4     outdoors landscape beach sky nature rural nope...          1         0   \n",
       "...                                                 ...        ...       ...   \n",
       "8052  outdoors nature scenery landscape water land o...          0         1   \n",
       "8053      human person patient therapy massage heel spa          0         1   \n",
       "8054                    plant paper text flower blossom          0         1   \n",
       "8055           person human finger hand dating face arm          0         1   \n",
       "8056           human person patient massage therapy spa          0         1   \n",
       "\n",
       "      available  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "8052          1  \n",
       "8053          1  \n",
       "8054          1  \n",
       "8055          1  \n",
       "8056          1  \n",
       "\n",
       "[8057 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_published = df.loc[df.query('available == 1 and published == 1').index]\n",
    "df_disabled = df.loc[df.query('available == 1 and disabled == 1').index]\n",
    "\n",
    "df_all = pd.concat([df_published, df_disabled], ignore_index=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import tqdm\n",
    "from torchvision import transforms\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "def get_pretrained_image_model():\n",
    "    model = torchvision.models.vgg16(pretrained=True)\n",
    "    model = nn.Sequential(*list(model.children())[:-1])\n",
    "    return model\n",
    "\n",
    "\n",
    "def extract_image_features(df_all):\n",
    "    pretrained_model = get_pretrained_image_model()\n",
    "    \n",
    "    for param in pretrained_model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    pretrained_model.eval()\n",
    "    \n",
    "    \n",
    "    if train_on_gpu:\n",
    "        pretrained_model = pretrained_model.cuda()\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    \n",
    "    id_to_features = {}    \n",
    "    for i, row in tqdm.tqdm(df_all.iterrows(), total=len(df_all)):\n",
    "        _id = row['_id']\n",
    "        \n",
    "        img = Image.open(os.path.join(all_images_path, _id + '.jpg')).convert(\"RGB\")\n",
    "        \n",
    "        img = transformer(img)\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            img = img.cuda()\n",
    "            \n",
    "        img_rep = pretrained_model(img.unsqueeze(0))\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            img_rep = img_rep.cpu()\n",
    "            \n",
    "        \n",
    "        img_rep = img_rep.numpy().squeeze().flatten()\n",
    "        \n",
    "        id_to_features[_id] = img_rep\n",
    "        \n",
    "    \n",
    "    \n",
    "    return id_to_features\n",
    "        \n",
    "        \n",
    "id_to_image_features_file = 'flair_vgg16_image_features.pkl'\n",
    "\n",
    "# id_to_image_features = extract_image_features(df_all)\n",
    "# with open(id_to_image_features_file, 'wb') as f:\n",
    "#     pickle.dump(id_to_image_features, f)\n",
    "\n",
    "\n",
    "# id_to_image_features = None\n",
    "# with open(id_to_image_features_file, 'rb') as f:\n",
    "#     id_to_image_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from where i would rather be again what an epic spot hamiltonisland such a beautiful eye snack around every corner and up every hill i will be back if you are looking for paradise in our own back yard i couldn t recommend this place more getting around the island on golf buggies snorkling eating amazing seafood getting friendly with the cockatoos it s all here thanks for an awesome holiday darreng 18 shaes amandabaker 0419 paradise hamiltonisland holiday australia whitsundays beauty takemeback'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.iloc[171]['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/efficientnet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-27 13:24:46,889 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/twitter.gensim.vectors.npy not found in cache, downloading to /tmp/tmps6tx6hzr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477405728/477405728 [00:51<00:00, 9252807.53B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-27 13:25:39,295 copying /tmp/tmps6tx6hzr to cache at /home/ec2-user/.flair/embeddings/twitter.gensim.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-27 13:25:39,722 removing temp file /tmp/tmps6tx6hzr\n",
      "2020-03-27 13:25:40,452 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/twitter.gensim not found in cache, downloading to /tmp/tmpo6y6w4s0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68268001/68268001 [00:07<00:00, 8639669.83B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-27 13:25:49,141 copying /tmp/tmpo6y6w4s0 to cache at /home/ec2-user/.flair/embeddings/twitter.gensim\n",
      "2020-03-27 13:25:49,207 removing temp file /tmp/tmpo6y6w4s0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "from flair.embeddings import FlairEmbeddings, DocumentPoolEmbeddings, Sentence, WordEmbeddings\n",
    "\n",
    "def extract_text_features(df_all):\n",
    "    \n",
    "    flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "    flair_embedding_backward = FlairEmbeddings('news-backward')\n",
    "    twitter_embedding = WordEmbeddings('twitter')\n",
    "\n",
    "    document_embedding = DocumentPoolEmbeddings([\n",
    "        twitter_embedding,\n",
    "        flair_embedding_forward, \n",
    "        flair_embedding_backward\n",
    "    ])\n",
    "\n",
    "    id_to_text_features = {}\n",
    "    for i, row in tqdm.tqdm(df_all.iterrows(), total=len(df_all)):    \n",
    "        message = row['message']\n",
    "        _id = row['_id']\n",
    "        sentence = Sentence(str(message))\n",
    "        document_embedding.embed(sentence)\n",
    "        embedding = sentence.get_embedding().cpu().detach().numpy().flatten()\n",
    "        id_to_text_features[_id] = embedding\n",
    "        \n",
    "    return id_to_text_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8057/8057 [30:41<00:00,  4.38it/s]  \n"
     ]
    }
   ],
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_text_features_twitter_file = 'f_text_features_twitter.pkl'\n",
    "with open(id_to_text_features_twitter_file, 'wb') as f:\n",
    "    pickle.dump(id_to_text_features, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:efficientnet]",
   "language": "python",
   "name": "conda-env-efficientnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
